{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZfFjZmhoHfI",
        "outputId": "5b9a6ba5-f595-4299-e220-fdb10f9cdcf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puFpDPEkOwJO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vNHSKijQIaOg",
        "outputId": "d3564ac6-8148-4289-836e-f3f858111050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow_federated\n",
            "  Downloading tensorflow_federated-0.87.0-py3-none-manylinux_2_31_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting attrs~=23.1 (from tensorflow_federated)\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: cachetools~=5.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (5.5.0)\n",
            "Requirement already satisfied: dm-tree==0.1.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (0.1.8)\n",
            "Collecting dp-accounting==0.4.3 (from tensorflow_federated)\n",
            "  Downloading dp_accounting-0.4.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting google-vizier==0.1.11 (from tensorflow_federated)\n",
            "  Downloading google_vizier-0.1.11-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jaxlib==0.4.14 (from tensorflow_federated)\n",
            "  Downloading jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting jax==0.4.14 (from tensorflow_federated)\n",
            "  Downloading jax-0.4.14.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of tensorflow-federated to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow_federated\n",
            "  Downloading tensorflow_federated-0.86.0-py3-none-manylinux_2_31_x86_64.whl.metadata (19 kB)\n",
            "  Downloading tensorflow_federated-0.85.0-py3-none-manylinux_2_31_x86_64.whl.metadata (19 kB)\n",
            "  Downloading tensorflow_federated-0.84.0-py3-none-manylinux_2_31_x86_64.whl.metadata (19 kB)\n",
            "Collecting portpicker~=1.6 (from tensorflow_federated)\n",
            "  Downloading portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting scipy~=1.9.3 (from tensorflow_federated)\n",
            "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-model-optimization==0.7.5 (from tensorflow_federated)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "Collecting tensorflow-privacy==0.9.0 (from tensorflow_federated)\n",
            "  Downloading tensorflow_privacy-0.9.0-py3-none-any.whl.metadata (763 bytes)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tqdm~=4.64 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (4.66.6)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting googleapis-common-protos==1.61.0 (from tensorflow_federated)\n",
            "  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow)\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.10/dist-packages (from dp-accounting==0.4.3->tensorflow_federated) (1.3.0)\n",
            "Collecting attrs~=23.1 (from tensorflow_federated)\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting grpcio-tools>=1.35.0 (from google-vizier==0.1.11->tensorflow_federated)\n",
            "  Downloading grpcio_tools-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting sqlalchemy<=1.4.20,>=1.4 (from google-vizier==0.1.11->tensorflow_federated)\n",
            "  Downloading SQLAlchemy-1.4.20.tar.gz (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging (from tensorflow-addons)\n",
            "  Downloading packaging-22.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy==0.9.0->tensorflow_federated) (1.5.2)\n",
            "Collecting tensorflow-probability~=0.22.0 (from tensorflow-privacy==0.9.0->tensorflow_federated)\n",
            "  Downloading tensorflow_probability-0.22.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow_federated) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow_federated) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker~=1.6->tensorflow_federated) (5.9.5)\n",
            "Collecting numpy~=1.25 (from tensorflow_federated)\n",
            "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-tools>=1.35.0 (from google-vizier==0.1.11->tensorflow_federated)\n",
            "  Downloading grpcio_tools-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_tools-1.65.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_tools-1.63.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier==0.1.11->tensorflow_federated) (3.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow_federated) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow_federated) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
            "Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_federated-0.84.0-py3-none-manylinux_2_31_x86_64.whl (71.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dp_accounting-0.4.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_vizier-0.1.11-py3-none-any.whl (721 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.6/721.6 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl (73.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_privacy-0.9.0-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-22.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
            "Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_probability-0.22.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: jax, sqlalchemy\n",
            "  Building wheel for jax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.4.14-py3-none-any.whl size=1535361 sha256=3270feb82ec9f3e691e037363875a24eaa54e0c4186707ce25f9df16202b646f\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/52/e7/dfa571c9f9b879e3facaa1584f52be04c4c3d1e14054ef40ab\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.4.20-cp310-cp310-linux_x86_64.whl size=1529858 sha256=29e47d9edc10146e8b29238bd68af92253c2f57b99a21ce6bcc2d15c38a8d0b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/42/20/a958989c470cc1a6fe1d1279b0193f0e508161327fc3d951d9\n",
            "Successfully built jax sqlalchemy\n",
            "Installing collected packages: wrapt, typing-extensions, typeguard, tensorflow-estimator, sqlalchemy, portpicker, packaging, numpy, keras, grpcio-tools, googleapis-common-protos, attrs, tensorflow-probability, tensorflow-model-optimization, tensorflow-addons, scipy, ml-dtypes, google-vizier, jaxlib, jax, google-auth-oauthlib, dp-accounting, tensorboard, tensorflow, tensorflow-privacy, tensorflow_federated\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: portpicker\n",
            "    Found existing installation: portpicker 1.5.2\n",
            "    Uninstalling portpicker-1.5.2:\n",
            "      Successfully uninstalled portpicker-1.5.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.5.0\n",
            "    Uninstalling keras-3.5.0:\n",
            "      Successfully uninstalled keras-3.5.0\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.66.0\n",
            "    Uninstalling googleapis-common-protos-1.66.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.66.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 24.2.0\n",
            "    Uninstalling attrs-24.2.0:\n",
            "      Successfully uninstalled attrs-24.2.0\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.24.0\n",
            "    Uninstalling tensorflow-probability-0.24.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.24.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.33\n",
            "    Uninstalling jaxlib-0.4.33:\n",
            "      Successfully uninstalled jaxlib-0.4.33\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.33\n",
            "    Uninstalling jax-0.4.33:\n",
            "      Successfully uninstalled jax-0.4.33\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\n",
            "chex 0.1.87 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "chex 0.1.87 requires jaxlib>=0.4.27, but you have jaxlib 0.4.14 which is incompatible.\n",
            "flax 0.8.5 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "google-colab 1.0.0 requires portpicker==1.5.2, but you have portpicker 1.6.0 which is incompatible.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.20 which is incompatible.\n",
            "langchain-core 0.3.19 requires packaging<25,>=23.2, but you have packaging 22.0 which is incompatible.\n",
            "langchain-core 0.3.19 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "openai 1.54.4 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "optax 0.2.4 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "optax 0.2.4 requires jaxlib>=0.4.27, but you have jaxlib 0.4.14 which is incompatible.\n",
            "orbax-checkpoint 0.6.4 requires jax>=0.4.26, but you have jax 0.4.14 which is incompatible.\n",
            "pydantic 2.9.2 requires typing-extensions>=4.6.1; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.23.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "sphinx 8.1.3 requires packaging>=23.0, but you have packaging 22.0 which is incompatible.\n",
            "tensorstore 0.1.68 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.14.1 which is incompatible.\n",
            "torch 2.5.1+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "xarray 2024.10.0 requires packaging>=23.1, but you have packaging 22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed attrs-23.1.0 dp-accounting-0.4.3 google-auth-oauthlib-1.0.0 google-vizier-0.1.11 googleapis-common-protos-1.61.0 grpcio-tools-1.62.3 jax-0.4.14 jaxlib-0.4.14 keras-2.14.0 ml-dtypes-0.2.0 numpy-1.25.2 packaging-22.0 portpicker-1.6.0 scipy-1.9.3 sqlalchemy-1.4.20 tensorboard-2.14.1 tensorflow-2.14.1 tensorflow-addons-0.23.0 tensorflow-estimator-2.14.0 tensorflow-model-optimization-0.7.5 tensorflow-privacy-0.9.0 tensorflow-probability-0.22.1 tensorflow_federated-0.84.0 typeguard-2.13.3 typing-extensions-4.5.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy",
                  "portpicker"
                ]
              },
              "id": "a445b9e5e53a48db93eed089f3a46b86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-federated==0.41.0\n",
            "  Downloading tensorflow_federated-0.41.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: absl-py==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated==0.41.0) (1.4.0)\n",
            "Collecting attrs~=21.4 (from tensorflow-federated==0.41.0)\n",
            "  Downloading attrs-21.4.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting cachetools~=3.1 (from tensorflow-federated==0.41.0)\n",
            "  Downloading cachetools-3.1.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting dm-tree==0.1.7 (from tensorflow-federated==0.41.0)\n",
            "  Downloading dm_tree-0.1.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting dp-accounting==0.3.0 (from tensorflow-federated==0.41.0)\n",
            "  Downloading dp_accounting-0.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting farmhashpy==0.4.0 (from tensorflow-federated==0.41.0)\n",
            "  Downloading farmhashpy-0.4.0.tar.gz (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: grpcio~=1.46 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated==0.41.0) (1.68.0)\n",
            "INFO: pip is looking at multiple versions of tensorflow-federated to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 0.4.32\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 0.34.0 Requires-Python ~=3.9.0; 0.36.0 Requires-Python ~=3.9.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement jaxlib==0.3.14 (from tensorflow-federated) (from versions: 0.4.6, 0.4.7, 0.4.9, 0.4.10, 0.4.11, 0.4.12, 0.4.13, 0.4.14, 0.4.16, 0.4.17, 0.4.18, 0.4.19, 0.4.20, 0.4.21, 0.4.22, 0.4.23, 0.4.24, 0.4.25, 0.4.26, 0.4.27, 0.4.28, 0.4.29, 0.4.30, 0.4.31, 0.4.33, 0.4.34, 0.4.35)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for jaxlib==0.3.14\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting scipy==1.10.1\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy==1.10.1) (1.25.2)\n",
            "Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.9.3\n",
            "    Uninstalling scipy-1.9.3:\n",
            "      Successfully uninstalled scipy-1.9.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "optax 0.2.4 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "optax 0.2.4 requires jaxlib>=0.4.27, but you have jaxlib 0.4.14 which is incompatible.\n",
            "orbax-checkpoint 0.6.4 requires jax>=0.4.26, but you have jax 0.4.14 which is incompatible.\n",
            "tensorflow-federated 0.84.0 requires scipy~=1.9.3, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.10.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:jax._src.xla_bridge:Jax plugin configuration error: Exception when calling jax_plugins.xla_cuda12.initialize()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/xla_bridge.py\", line 438, in discover_pjrt_plugins\n",
            "    plugin_module.initialize()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax_plugins/xla_cuda12/__init__.py\", line 85, in initialize\n",
            "    options = xla_client.generate_pjrt_gpu_plugin_options()\n",
            "AttributeError: module 'jaxlib.xla_client' has no attribute 'generate_pjrt_gpu_plugin_options'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries for federated learning\n",
        "!pip install tensorflow tensorflow-addons tensorflow_federated\n",
        "!pip install tensorflow-federated==0.41.0\n",
        "!pip install scipy==1.10.1\n",
        "\n",
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Mount Google Drive to access dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLtxhfaflKz4"
      },
      "source": [
        "federation learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G8PcROlMfSTv",
        "outputId": "64555701-71cc-40d2-e04e-2c73db1a4190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_federated\n",
            "  Downloading tensorflow_federated-0.87.0-py3-none-manylinux_2_31_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: absl-py==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (1.4.0)\n",
            "Collecting attrs~=23.1 (from tensorflow_federated)\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: cachetools~=5.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (5.5.0)\n",
            "Requirement already satisfied: dm-tree==0.1.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (0.1.8)\n",
            "Collecting dp-accounting==0.4.3 (from tensorflow_federated)\n",
            "  Downloading dp_accounting-0.4.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting google-vizier==0.1.11 (from tensorflow_federated)\n",
            "  Downloading google_vizier-0.1.11-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: grpcio~=1.46 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (1.67.1)\n",
            "Collecting jaxlib==0.4.14 (from tensorflow_federated)\n",
            "  Downloading jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting jax==0.4.14 (from tensorflow_federated)\n",
            "  Downloading jax-0.4.14.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ml-dtypes==0.2.*,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (0.2.0)\n",
            "Requirement already satisfied: numpy~=1.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (1.26.4)\n",
            "Collecting portpicker~=1.6 (from tensorflow_federated)\n",
            "  Downloading portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting scipy~=1.9.3 (from tensorflow_federated)\n",
            "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-model-optimization==0.7.5 (from tensorflow_federated)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "Collecting tensorflow-privacy==0.9.0 (from tensorflow_federated)\n",
            "  Downloading tensorflow_privacy-0.9.0-py3-none-any.whl.metadata (763 bytes)\n",
            "Collecting tensorflow==2.14.*,>=2.14.0 (from tensorflow_federated)\n",
            "  Downloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tqdm~=4.64 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (4.66.6)\n",
            "Collecting typing-extensions==4.5.*,>=4.5.0 (from tensorflow_federated)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting googleapis-common-protos==1.61.0 (from tensorflow_federated)\n",
            "  Downloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.10/dist-packages (from dp-accounting==0.4.3->tensorflow_federated) (1.3.0)\n",
            "Collecting attrs~=23.1 (from tensorflow_federated)\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: protobuf>=3.6 in /usr/local/lib/python3.10/dist-packages (from google-vizier==0.1.11->tensorflow_federated) (4.25.5)\n",
            "Collecting grpcio-tools>=1.35.0 (from google-vizier==0.1.11->tensorflow_federated)\n",
            "  Downloading grpcio_tools-1.67.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting sqlalchemy<=1.4.20,>=1.4 (from google-vizier==0.1.11->tensorflow_federated)\n",
            "  Downloading SQLAlchemy-1.4.20.tar.gz (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax==0.4.14->tensorflow_federated) (3.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (18.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (24.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.37.1)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting packaging (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n",
            "  Downloading packaging-22.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy==0.9.0->tensorflow_federated) (1.5.2)\n",
            "Collecting tensorflow-probability~=0.22.0 (from tensorflow-privacy==0.9.0->tensorflow_federated)\n",
            "  Downloading tensorflow_probability-0.22.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow_federated) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow_federated) (3.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker~=1.6->tensorflow_federated) (5.9.5)\n",
            "Collecting numpy~=1.25 (from tensorflow_federated)\n",
            "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.44.0)\n",
            "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-tools>=1.35.0 (from google-vizier==0.1.11->tensorflow_federated)\n",
            "  Downloading grpcio_tools-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_tools-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.63.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_tools-1.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting greenlet!=0.4.17 (from sqlalchemy<=1.4.20,>=1.4->google-vizier==0.1.11->tensorflow_federated)\n",
            "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.0.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow_federated) (5.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow_federated) (3.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.2.2)\n",
            "Downloading tensorflow_federated-0.87.0-py3-none-manylinux_2_31_x86_64.whl (71.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dp_accounting-0.4.3-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_vizier-0.1.11-py3-none-any.whl (721 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.6/721.6 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading googleapis_common_protos-1.61.0-py2.py3-none-any.whl (230 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl (73.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_privacy-0.9.0-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
            "Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-22.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_probability-0.22.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: jax, sqlalchemy\n",
            "  Building wheel for jax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.4.14-py3-none-any.whl size=1535358 sha256=42583d543948ac9cc2d5d2120bf11989bce60b9f8cc27a6c0790bc153d802f22\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/52/e7/dfa571c9f9b879e3facaa1584f52be04c4c3d1e14054ef40ab\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.4.20-cp310-cp310-linux_x86_64.whl size=1529845 sha256=b5c85a6656252380a871916227ce6794802475d127b026bc9c81f0df8fcf179c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/42/20/a958989c470cc1a6fe1d1279b0193f0e508161327fc3d951d9\n",
            "Successfully built jax sqlalchemy\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, portpicker, packaging, numpy, keras, grpcio-tools, greenlet, googleapis-common-protos, attrs, tensorflow-probability, tensorflow-model-optimization, sqlalchemy, scipy, jaxlib, jax, google-vizier, google-auth-oauthlib, dp-accounting, tensorboard, tensorflow, tensorflow-privacy, tensorflow_federated\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: portpicker\n",
            "    Found existing installation: portpicker 1.5.2\n",
            "    Uninstalling portpicker-1.5.2:\n",
            "      Successfully uninstalled portpicker-1.5.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.65.0\n",
            "    Uninstalling googleapis-common-protos-1.65.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.65.0\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 24.2.0\n",
            "    Uninstalling attrs-24.2.0:\n",
            "      Successfully uninstalled attrs-24.2.0\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.24.0\n",
            "    Uninstalling tensorflow-probability-0.24.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.24.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.33\n",
            "    Uninstalling jaxlib-0.4.33:\n",
            "      Successfully uninstalled jaxlib-0.4.33\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.33\n",
            "    Uninstalling jax-0.4.33:\n",
            "      Successfully uninstalled jax-0.4.33\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.87 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "chex 0.1.87 requires jaxlib>=0.4.27, but you have jaxlib 0.4.14 which is incompatible.\n",
            "flax 0.8.5 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "google-colab 1.0.0 requires portpicker==1.5.2, but you have portpicker 1.6.0 which is incompatible.\n",
            "pydantic 2.9.2 requires typing-extensions>=4.6.1; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.23.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.14.1 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.14.1 which is incompatible.\n",
            "torch 2.5.0+cpu requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed attrs-23.1.0 dp-accounting-0.4.3 google-auth-oauthlib-1.0.0 google-vizier-0.1.11 googleapis-common-protos-1.61.0 greenlet-3.1.1 grpcio-tools-1.62.3 jax-0.4.14 jaxlib-0.4.14 keras-2.14.0 numpy-1.25.2 packaging-22.0 portpicker-1.6.0 scipy-1.9.3 sqlalchemy-1.4.20 tensorboard-2.14.1 tensorflow-2.14.1 tensorflow-estimator-2.14.0 tensorflow-model-optimization-0.7.5 tensorflow-privacy-0.9.0 tensorflow-probability-0.22.1 tensorflow_federated-0.87.0 typing-extensions-4.5.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "4f626ad124ea4c93a96f98647bdd94b4",
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy",
                  "portpicker"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.8.1\n",
            "  Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting numpy<1.25.0,>=1.17.3 (from scipy==1.8.1)\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.9.3\n",
            "    Uninstalling scipy-1.9.3:\n",
            "      Successfully uninstalled scipy-1.9.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.87 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "chex 0.1.87 requires jaxlib>=0.4.27, but you have jaxlib 0.4.14 which is incompatible.\n",
            "flax 0.8.5 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "scikit-image 0.24.0 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\n",
            "tensorflow-federated 0.87.0 requires numpy~=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow-federated 0.87.0 requires scipy~=1.9.3, but you have scipy 1.8.1 which is incompatible.\n",
            "tensorflow-privacy 0.9.0 requires scipy~=1.9, but you have scipy 1.8.1 which is incompatible.\n",
            "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.14.1 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4 scipy-1.8.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "7608858d6f794988abb183d6da209faf",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install tensorflow_federated\n",
        "!pip install scipy==1.8.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPFqvfi4l69x"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_federated as tff\n",
        "import tensorflow_addons as tfa  # for Group Normalization\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zun_lhO1Lfcb",
        "outputId": "aac25d56-87ad-42e2-c497-eaa75f4d7b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_federated in /usr/local/lib/python3.10/dist-packages (0.87.0)\n",
            "Requirement already satisfied: absl-py==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (1.4.0)\n",
            "Requirement already satisfied: attrs~=23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (23.1.0)\n",
            "Requirement already satisfied: cachetools~=5.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (5.5.0)\n",
            "Requirement already satisfied: dm-tree==0.1.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (0.1.8)\n",
            "Requirement already satisfied: dp-accounting==0.4.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (0.4.3)\n",
            "Requirement already satisfied: google-vizier==0.1.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (0.1.11)\n",
            "Requirement already satisfied: grpcio~=1.46 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (1.67.1)\n",
            "Requirement already satisfied: jaxlib==0.4.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (0.4.14)\n",
            "Requirement already satisfied: jax==0.4.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (0.4.14)\n",
            "Requirement already satisfied: ml-dtypes==0.2.*,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (0.2.0)\n",
            "Collecting numpy~=1.25 (from tensorflow_federated)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: portpicker~=1.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (1.6.0)\n",
            "Collecting scipy~=1.9.3 (from tensorflow_federated)\n",
            "  Using cached scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Requirement already satisfied: tensorflow-model-optimization==0.7.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (0.7.5)\n",
            "Requirement already satisfied: tensorflow-privacy==0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (0.9.0)\n",
            "Requirement already satisfied: tensorflow==2.14.*,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (2.14.1)\n",
            "Requirement already satisfied: tqdm~=4.64 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions==4.5.*,>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (4.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos==1.61.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_federated) (1.61.0)\n",
            "Requirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.10/dist-packages (from dp-accounting==0.4.3->tensorflow_federated) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.6 in /usr/local/lib/python3.10/dist-packages (from google-vizier==0.1.11->tensorflow_federated) (4.25.5)\n",
            "Requirement already satisfied: grpcio-tools>=1.35.0 in /usr/local/lib/python3.10/dist-packages (from google-vizier==0.1.11->tensorflow_federated) (1.62.3)\n",
            "Requirement already satisfied: sqlalchemy<=1.4.20,>=1.4 in /usr/local/lib/python3.10/dist-packages (from google-vizier==0.1.11->tensorflow_federated) (1.4.20)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax==0.4.14->tensorflow_federated) (3.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (18.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (22.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.37.1)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.14.0)\n",
            "Requirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy==0.9.0->tensorflow_federated) (1.5.2)\n",
            "Requirement already satisfied: tensorflow-probability~=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy==0.9.0->tensorflow_federated) (0.22.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow_federated) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0->tensorflow_federated) (3.5.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker~=1.6->tensorflow_federated) (5.9.5)\n",
            "Collecting numpy~=1.25 (from tensorflow_federated)\n",
            "  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.45.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier==0.1.11->tensorflow_federated) (3.1.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.1.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow_federated) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow_federated) (3.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.*,>=2.14.0->tensorflow_federated) (3.2.2)\n",
            "Using cached scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
            "Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.8.1\n",
            "    Uninstalling scipy-1.8.1:\n",
            "      Successfully uninstalled scipy-1.8.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\n",
            "chex 0.1.87 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "chex 0.1.87 requires jaxlib>=0.4.27, but you have jaxlib 0.4.14 which is incompatible.\n",
            "flax 0.8.5 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "optax 0.2.4 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "optax 0.2.4 requires jaxlib>=0.4.27, but you have jaxlib 0.4.14 which is incompatible.\n",
            "orbax-checkpoint 0.6.4 requires jax>=0.4.26, but you have jax 0.4.14 which is incompatible.\n",
            "tensorstore 0.1.68 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.14.1 which is incompatible.\n",
            "xarray 2024.10.0 requires packaging>=23.1, but you have packaging 22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.25.2 scipy-1.9.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "f1ebde0ee93f4287bea8641b2be1c405",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.8.1\n",
            "  Using cached scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting numpy<1.25.0,>=1.17.3 (from scipy==1.8.1)\n",
            "  Using cached numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Using cached scipy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "Using cached numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Installing collected packages: numpy, scipy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.9.3\n",
            "    Uninstalling scipy-1.9.3:\n",
            "      Successfully uninstalled scipy-1.9.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires scipy>=1.10.0, but you have scipy 1.8.1 which is incompatible.\n",
            "arviz 0.20.0 requires scipy>=1.9.0, but you have scipy 1.8.1 which is incompatible.\n",
            "chex 0.1.87 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "chex 0.1.87 requires jaxlib>=0.4.27, but you have jaxlib 0.4.14 which is incompatible.\n",
            "flax 0.8.5 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "optax 0.2.4 requires jax>=0.4.27, but you have jax 0.4.14 which is incompatible.\n",
            "optax 0.2.4 requires jaxlib>=0.4.27, but you have jaxlib 0.4.14 which is incompatible.\n",
            "orbax-checkpoint 0.6.4 requires jax>=0.4.26, but you have jax 0.4.14 which is incompatible.\n",
            "scikit-image 0.24.0 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\n",
            "tensorflow-federated 0.87.0 requires numpy~=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow-federated 0.87.0 requires scipy~=1.9.3, but you have scipy 1.8.1 which is incompatible.\n",
            "tensorflow-privacy 0.9.0 requires scipy~=1.9, but you have scipy 1.8.1 which is incompatible.\n",
            "tensorstore 0.1.68 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.14.1 which is incompatible.\n",
            "xarray 2024.10.0 requires packaging>=23.1, but you have packaging 22.0 which is incompatible.\n",
            "xarray-einstats 0.8.0 requires scipy>=1.9, but you have scipy 1.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4 scipy-1.8.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "ce633f7de44f4d4b8336f99350fc1d43",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install tensorflow_federated\n",
        "!pip install scipy==1.8.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-4M6KpUJK_X",
        "outputId": "84ae2361-b4a4-4191-bd0d-7ee62965d0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully split and distributed among client folders.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Path to the main folder containing your categories in Google Drive\n",
        "DATASET_PATH = '/content/drive/MyDrive/training'\n",
        "\n",
        "# Number of clients to simulate\n",
        "NUM_CLIENTS = 3\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Create folders for each client\n",
        "client_folders = [f'client_{i+1}' for i in range(NUM_CLIENTS)]\n",
        "for client_folder in client_folders:\n",
        "    os.makedirs(os.path.join(DATASET_PATH, client_folder), exist_ok=True)\n",
        "\n",
        "# Distribute images across clients\n",
        "for category in os.listdir(DATASET_PATH):\n",
        "    category_path = os.path.join(DATASET_PATH, category)\n",
        "    if os.path.isdir(category_path) and category[0].isdigit():  # Ensure it's a valid category folder\n",
        "        # List all images in the category folder\n",
        "        images = [img for img in os.listdir(category_path) if img.endswith(('jpg', 'jpeg', 'png'))]\n",
        "        random.shuffle(images)\n",
        "\n",
        "        # Calculate the number of images for each client\n",
        "        split_size = len(images) // NUM_CLIENTS\n",
        "        remainder = len(images) % NUM_CLIENTS\n",
        "\n",
        "        # Assign images to each client folder\n",
        "        for i, client_folder in enumerate(client_folders):\n",
        "            client_category_path = os.path.join(DATASET_PATH, client_folder, category)\n",
        "            os.makedirs(client_category_path, exist_ok=True)\n",
        "\n",
        "            # Determine split for current client\n",
        "            start_index = i * split_size + min(i, remainder)\n",
        "            end_index = start_index + split_size + (1 if i < remainder else 0)\n",
        "            client_images = images[start_index:end_index]\n",
        "\n",
        "            # Copy images to the client’s category folder\n",
        "            for image in client_images:\n",
        "                src = os.path.join(category_path, image)\n",
        "                dst = os.path.join(client_category_path, image)\n",
        "                shutil.copy(src, dst)\n",
        "\n",
        "print(\"Data successfully split and distributed among client folders.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "# Define the Keras model creation function\n",
        "def create_model(model_type='resnet'):\n",
        "    if model_type == 'resnet':\n",
        "        base_model = tf.keras.applications.ResNet50(\n",
        "            include_top=False, weights='imagenet', input_shape=(224, 224, 3)\n",
        "        )\n",
        "    elif model_type == 'convnext':\n",
        "        base_model = tf.keras.applications.ConvNeXtBase(\n",
        "            include_top=False, weights='imagenet', input_shape=(224, 224, 3)\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported model type\")\n",
        "\n",
        "    base_model.trainable = False  # Freeze the base model layers\n",
        "\n",
        "    # Add custom layers on top\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(8, activation='softmax')  # Assuming 8 classes\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define TFF model function\n",
        "def model_fn():\n",
        "    keras_model = create_model(model_type='resnet')  # Change 'resnet' to 'convnext' if desired\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    input_spec = (\n",
        "        tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "    )\n",
        "\n",
        "    # Return a TFF model from Keras model\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model=keras_model,\n",
        "        input_spec=input_spec,\n",
        "        loss=loss_fn,\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "# Correct optimizer setup for TFF with optimizer factories\n",
        "client_optimizer_fn = tff.learning.optimizers.build_adam(learning_rate=0.001)\n",
        "server_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=1.0, momentum=0.9)\n",
        "\n",
        "# Set up federated learning process using FedAvg\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=model_fn,\n",
        "    client_optimizer_fn=client_optimizer_fn,\n",
        "    server_optimizer_fn=server_optimizer_fn\n",
        ")\n",
        "print(\"Federated model setup complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWv6kekoKWqw",
        "outputId": "3876267a-740a-4c3b-c399-afb7ef596210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Federated model setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK2_MMsz74lR",
        "outputId": "33c2d87b-aa87-44d6-db3b-341f18b99414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Found 1324 files belonging to 7 classes.\n",
            "Found 1324 files belonging to 7 classes.\n",
            "Found 1324 files belonging to 7 classes.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_federated as tff\n",
        "import tensorflow_addons as tfa  # for Group Normalization\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Path to dataset on Google Drive\n",
        "DATASET_PATH = '/content/drive/MyDrive/clients'  # Update with your actual path\n",
        "\n",
        "# Load client data\n",
        "def load_client_data():\n",
        "    client_data = {}\n",
        "    client_folders = os.listdir(DATASET_PATH)\n",
        "    for client_id in client_folders:\n",
        "        client_folder = os.path.join(DATASET_PATH, client_id)\n",
        "        datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "        client_dataset = datagen.flow_from_directory(\n",
        "            client_folder,\n",
        "            target_size=(128, 128),  # Reduced image size for faster training\n",
        "            batch_size=16,           # Reduced batch size for less memory use\n",
        "            class_mode='sparse'\n",
        "        )\n",
        "        client_data[client_id] = client_dataset\n",
        "    return client_data\n",
        "\n",
        "client_data = load_client_data()\n",
        "client_ids = list(client_data.keys())\n",
        "\n",
        "# Create federated dataset\n",
        "def make_federated_data(client_data, client_ids):\n",
        "    return [\n",
        "        tf.data.Dataset.from_generator(\n",
        "            lambda: client_data[client_id],\n",
        "            output_signature=(\n",
        "                tf.TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32),\n",
        "                tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "            )\n",
        "        ) for client_id in client_ids\n",
        "    ]\n",
        "\n",
        "# Replace BatchNorm with GroupNorm in a model\n",
        "def replace_batch_norm_with_group_norm(model):\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "            new_layer = tfa.layers.GroupNormalization(groups=8, axis=-1, name=layer.name)\n",
        "            model._layers[model._layers.index(layer)] = new_layer\n",
        "    return model\n",
        "\n",
        "# Model function with Group Normalization\n",
        "def model_fn():\n",
        "    base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(7, activation='softmax')  # 7 classes for retinal diseases\n",
        "    ])\n",
        "    model = replace_batch_norm_with_group_norm(model)\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model=model,\n",
        "        input_spec=(\n",
        "            tf.TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "        ),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "# Define TFF-compatible optimizers\n",
        "client_optimizer_fn = lambda: tff.learning.optimizers.build_sgdm(learning_rate=0.001)\n",
        "server_optimizer_fn = lambda: tff.learning.optimizers.build_sgdm(learning_rate=1.0)\n",
        "\n",
        "# Define federated training process\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=model_fn,\n",
        "    client_optimizer_fn=client_optimizer_fn,\n",
        "    server_optimizer_fn=server_optimizer_fn\n",
        ")\n",
        "\n",
        "# Initialize the federated process state\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "\n",
        "# Save final model weights\n",
        "final_model_weights = iterative_process.get_model_weights(state)\n",
        "\n",
        "# Load test data for evaluation\n",
        "TEST_DATA_PATH = '/content/drive/MyDrive/test_data'  # Update with your actual path\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    TEST_DATA_PATH,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=16,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "def evaluate_model_on_test_data(final_model_weights, test_data):\n",
        "    model = model_fn()._keras_model\n",
        "    model.set_weights(final_model_weights)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    results = model.evaluate(test_data)\n",
        "    print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")\n",
        "\n",
        "evaluate_model_on_test_data(final_model_weights, test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUxGkkr_Mz-m"
      },
      "outputs": [],
      "source": [
        "# Prepare federated data with label conversion\n",
        "def make_federated_data(client_data, client_ids):\n",
        "    return [\n",
        "        tf.data.Dataset.from_generator(\n",
        "            lambda: client_data[client_id],\n",
        "            output_signature=(\n",
        "                tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
        "                tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "            )\n",
        "        ).map(lambda x, y: (x, tf.cast(y, tf.int64)))  # Cast labels to int64\n",
        "        for client_id in client_ids\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0JutVmpUmpj",
        "outputId": "58302532-5dde-4bfc-bd08-b30987bc9d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features {\n",
            "  feature {\n",
            "    key: \"label\"\n",
            "    value {\n",
            "      int64_list {\n",
            "        value: 2\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  feature {\n",
            "    key: \"features\"\n",
            "    value {\n",
            "      float_list {\n",
            "        value: 0.223988429\n",
            "        value: 0.124604329\n",
            "        value: 0.40770039\n",
            "        value: -1.28168261\n",
            "        value: -1.63829803\n",
            "        value: 1.37349427\n",
            "        value: -0.331474811\n",
            "        value: -0.148675442\n",
            "        value: 0.167031422\n",
            "        value: 0.347179592\n",
            "        value: -0.435788929\n",
            "        value: -0.56327194\n",
            "        value: 0.866593\n",
            "        value: 0.0471149087\n",
            "        value: -1.21850514\n",
            "        value: -0.514519215\n",
            "        value: -2.03242493\n",
            "        value: -0.577840388\n",
            "        value: -0.118821159\n",
            "        value: 0.203882501\n",
            "        value: -0.189448923\n",
            "        value: 0.389787644\n",
            "        value: 1.11880362\n",
            "        value: -0.717685163\n",
            "        value: 0.661391556\n",
            "        value: -0.555879653\n",
            "        value: 2.6139555\n",
            "        value: -0.0206646472\n",
            "        value: 0.712839663\n",
            "        value: 0.276235342\n",
            "        value: 1.02142811\n",
            "        value: 1.09426093\n",
            "        value: 0.542429447\n",
            "        value: -0.849457085\n",
            "        value: -0.519686043\n",
            "        value: 0.127325892\n",
            "        value: -0.257477224\n",
            "        value: 0.2673693\n",
            "        value: 0.604637146\n",
            "        value: -0.645346224\n",
            "        value: 0.375877798\n",
            "        value: -0.0207935199\n",
            "        value: -0.0518767461\n",
            "        value: 0.528741598\n",
            "        value: -0.404499292\n",
            "        value: 1.01468527\n",
            "        value: 0.430106431\n",
            "        value: 0.373610765\n",
            "        value: -1.00229561\n",
            "        value: 0.295971096\n",
            "        value: -0.4139072\n",
            "        value: 0.678162575\n",
            "        value: 1.62043583\n",
            "        value: -1.04899073\n",
            "        value: -0.97735858\n",
            "        value: 0.746055126\n",
            "        value: 1.37351549\n",
            "        value: 0.316582143\n",
            "        value: 0.107337475\n",
            "        value: -0.472342491\n",
            "        value: 0.650232315\n",
            "        value: -1.44952536\n",
            "        value: 1.74685943\n",
            "        value: -1.12444544\n",
            "        value: 0.217647165\n",
            "        value: 0.105467185\n",
            "        value: -1.3797611\n",
            "        value: -0.0152001195\n",
            "        value: -0.250623047\n",
            "        value: -0.253221214\n",
            "        value: 0.681783795\n",
            "        value: 0.0402060039\n",
            "        value: -0.494905084\n",
            "        value: -0.492731571\n",
            "        value: -0.226809591\n",
            "        value: 1.08211291\n",
            "        value: 0.733098\n",
            "        value: 0.433474362\n",
            "        value: 0.632556081\n",
            "        value: -1.20707583\n",
            "        value: -0.16573444\n",
            "        value: -0.00412300229\n",
            "        value: 0.345705032\n",
            "        value: -0.985791326\n",
            "        value: 0.837462962\n",
            "        value: -1.16550577\n",
            "        value: -0.898952\n",
            "        value: -0.328437299\n",
            "        value: -0.307797372\n",
            "        value: 0.0345804952\n",
            "        value: -0.161102504\n",
            "        value: -0.655931\n",
            "        value: 0.467157125\n",
            "        value: 0.016187869\n",
            "        value: -0.011500299\n",
            "        value: -0.649568617\n",
            "        value: 0.0188716184\n",
            "        value: -0.31029591\n",
            "        value: -0.299310148\n",
            "        value: 0.718060493\n",
            "        value: 0.0793513954\n",
            "        value: 0.755048811\n",
            "        value: -1.73196065\n",
            "        value: -0.676466525\n",
            "        value: -0.836803854\n",
            "        value: -0.0679379\n",
            "        value: -0.519875765\n",
            "        value: 1.42070508\n",
            "        value: 0.13005355\n",
            "        value: -0.369614303\n",
            "        value: 1.38724077\n",
            "        value: -0.198487788\n",
            "        value: -0.28579095\n",
            "        value: 0.697714925\n",
            "        value: -0.241844565\n",
            "        value: 0.657268882\n",
            "        value: -0.445493579\n",
            "        value: 0.361024261\n",
            "        value: 1.48720467\n",
            "        value: -1.70937431\n",
            "        value: 0.0362928957\n",
            "        value: 1.26677251\n",
            "        value: -0.558221281\n",
            "        value: -0.573086679\n",
            "        value: 0.986748934\n",
            "        value: 0.161726922\n",
            "        value: 0.233087212\n",
            "        value: 0.587011456\n",
            "        value: 0.409572244\n",
            "        value: 0.387373865\n",
            "        value: 1.16427279\n",
            "        value: -0.178507492\n",
            "        value: -0.172282189\n",
            "        value: -2.56093359\n",
            "        value: 0.71489656\n",
            "        value: 0.103631899\n",
            "        value: -0.713692069\n",
            "        value: -0.763985515\n",
            "        value: -0.153494015\n",
            "        value: 0.582936049\n",
            "        value: 0.0694488585\n",
            "        value: -1.25440669\n",
            "        value: -1.79201961\n",
            "        value: -1.26591265\n",
            "        value: 0.499474108\n",
            "        value: -0.487133622\n",
            "        value: 0.206584692\n",
            "        value: 0.422463119\n",
            "        value: -1.34354281\n",
            "        value: 0.195220605\n",
            "        value: -1.45982361\n",
            "        value: 1.37972629\n",
            "        value: -1.22892261\n",
            "        value: -1.37824321\n",
            "        value: 0.182328731\n",
            "        value: -0.346276671\n",
            "        value: 1.21407664\n",
            "        value: -0.216677547\n",
            "        value: 0.0631703287\n",
            "        value: 0.665415168\n",
            "        value: 1.64743769\n",
            "        value: -0.157035753\n",
            "        value: 0.204684526\n",
            "        value: 0.811273575\n",
            "        value: 0.0117853172\n",
            "        value: 0.560030341\n",
            "        value: -0.20959723\n",
            "        value: -0.237794638\n",
            "        value: -0.671378732\n",
            "        value: 1.44984341\n",
            "        value: 0.0751342475\n",
            "        value: -1.11948872\n",
            "        value: 0.108088776\n",
            "        value: 0.271718979\n",
            "        value: -0.0683683902\n",
            "        value: -0.569436908\n",
            "        value: 1.13019013\n",
            "        value: -0.192301124\n",
            "        value: -0.632730722\n",
            "        value: 0.764248133\n",
            "        value: 0.830752373\n",
            "        value: -2.47589159\n",
            "        value: -1.21412694\n",
            "        value: -0.265225053\n",
            "        value: -0.597650528\n",
            "        value: -1.18453145\n",
            "        value: -0.606879473\n",
            "        value: -0.416537493\n",
            "        value: -0.344745576\n",
            "        value: -0.869744\n",
            "        value: -0.0183735602\n",
            "        value: 0.420223475\n",
            "        value: -0.0667829663\n",
            "        value: 0.452612102\n",
            "        value: -0.974446297\n",
            "        value: 0.505560756\n",
            "        value: -0.684988678\n",
            "        value: -0.275237292\n",
            "        value: -1.54495656\n",
            "        value: 0.61647737\n",
            "        value: -0.212707445\n",
            "        value: 0.483864456\n",
            "        value: -0.808002\n",
            "        value: -0.323399842\n",
            "        value: -0.0629459843\n",
            "        value: -0.295348108\n",
            "        value: 0.436009854\n",
            "        value: 1.76087165\n",
            "        value: 0.792281\n",
            "        value: 0.682230771\n",
            "        value: 1.01921213\n",
            "        value: 0.738715947\n",
            "        value: -0.701063633\n",
            "        value: -0.821364343\n",
            "        value: -0.530509949\n",
            "        value: -0.126240924\n",
            "        value: 1.74645543\n",
            "        value: 0.0547915958\n",
            "        value: -0.788682818\n",
            "        value: 1.04345703\n",
            "        value: -0.0924574137\n",
            "        value: 0.187161624\n",
            "        value: -0.264016271\n",
            "        value: 0.00997692\n",
            "        value: 0.910461843\n",
            "        value: -0.83093977\n",
            "        value: -0.609820902\n",
            "        value: 0.414654315\n",
            "        value: -0.112830028\n",
            "        value: 0.291696221\n",
            "        value: 0.236425892\n",
            "        value: -1.06766701\n",
            "        value: 0.792468429\n",
            "        value: 0.368612438\n",
            "        value: 0.428653687\n",
            "        value: 0.72108078\n",
            "        value: -0.307366669\n",
            "        value: 1.81437302\n",
            "        value: -0.0778445676\n",
            "        value: -0.588039517\n",
            "        value: -1.30943513\n",
            "        value: 0.331612289\n",
            "        value: -0.0026063025\n",
            "        value: 0.237355426\n",
            "        value: -0.682083905\n",
            "        value: -0.497980893\n",
            "        value: 0.0236852802\n",
            "        value: -0.260774553\n",
            "        value: 1.07730138\n",
            "        value: -0.606090188\n",
            "        value: 1.11527777\n",
            "        value: -0.462945104\n",
            "        value: 0.607204378\n",
            "        value: -0.0809172094\n",
            "        value: 0.153340727\n",
            "        value: -0.791672885\n",
            "        value: -0.0548196\n",
            "        value: -0.986788034\n",
            "        value: 1.20044971\n",
            "        value: -0.306697786\n",
            "        value: 2.96251535\n",
            "        value: 0.0850317776\n",
            "        value: 0.762743831\n",
            "        value: -0.291964352\n",
            "        value: 0.880459905\n",
            "        value: 0.951802969\n",
            "        value: -1.0553329\n",
            "        value: 0.73704505\n",
            "        value: 0.506742835\n",
            "        value: -0.072037138\n",
            "        value: -0.910547376\n",
            "        value: -1.61084676\n",
            "        value: 0.0782394558\n",
            "        value: -0.608813763\n",
            "        value: 1.32111704\n",
            "        value: 1.43219066\n",
            "        value: -2.42783427\n",
            "        value: -0.024068445\n",
            "        value: -0.0129981935\n",
            "        value: -2.3968358\n",
            "        value: 0.17800945\n",
            "        value: -0.178580642\n",
            "        value: -1.14173055\n",
            "        value: -0.449723542\n",
            "        value: 0.129746929\n",
            "        value: 0.751701891\n",
            "        value: -0.526391566\n",
            "        value: 0.146812975\n",
            "        value: -1.05206251\n",
            "        value: -0.387011409\n",
            "        value: -0.487572521\n",
            "        value: -0.735700667\n",
            "        value: 1.11800933\n",
            "        value: -0.0358738974\n",
            "        value: -0.878093123\n",
            "        value: 1.09463131\n",
            "        value: -0.612534463\n",
            "        value: -0.146543145\n",
            "        value: -0.08277601\n",
            "        value: -0.561337352\n",
            "        value: 0.442957878\n",
            "        value: 0.627517641\n",
            "        value: -0.428582132\n",
            "        value: -0.318424135\n",
            "        value: 1.01933169\n",
            "        value: -0.440989375\n",
            "        value: -0.405804783\n",
            "        value: -0.220163733\n",
            "        value: -1.15948749\n",
            "        value: 0.889173269\n",
            "        value: -0.595808625\n",
            "        value: 0.785323262\n",
            "        value: -0.0116910338\n",
            "        value: 0.259605\n",
            "        value: -0.216294974\n",
            "        value: -0.0438286141\n",
            "        value: -0.62219274\n",
            "        value: 0.0161191821\n",
            "        value: 0.248313278\n",
            "        value: -0.261423796\n",
            "        value: 0.962364\n",
            "        value: 0.347400963\n",
            "        value: -0.798303723\n",
            "        value: -0.101161718\n",
            "        value: -0.0375799723\n",
            "        value: -0.19091107\n",
            "        value: 0.344056785\n",
            "        value: -0.0830076933\n",
            "        value: 0.58881104\n",
            "        value: -0.710129201\n",
            "        value: -0.84330225\n",
            "        value: -1.50214624\n",
            "        value: 0.233656064\n",
            "        value: -0.266680121\n",
            "        value: -0.186794192\n",
            "        value: 0.216948226\n",
            "        value: 0.316729516\n",
            "        value: 0.686484933\n",
            "        value: 0.343667179\n",
            "        value: -0.760483503\n",
            "        value: 0.0361113697\n",
            "        value: 0.0455652922\n",
            "        value: 0.610367537\n",
            "        value: 0.134453416\n",
            "        value: -0.832899094\n",
            "        value: 0.79733634\n",
            "        value: -0.00203613937\n",
            "        value: 0.378546119\n",
            "        value: 0.0901863575\n",
            "        value: 0.26693055\n",
            "        value: -0.988916397\n",
            "        value: -0.712738693\n",
            "        value: -0.925177813\n",
            "        value: -1.22659326\n",
            "        value: -0.425510615\n",
            "        value: -0.0980259329\n",
            "        value: -0.267028064\n",
            "        value: 0.369854063\n",
            "        value: 1.63943458\n",
            "        value: -0.00163669884\n",
            "        value: -0.541088939\n",
            "        value: -0.278993577\n",
            "        value: 1.38521814\n",
            "        value: 0.260583222\n",
            "        value: -0.102907151\n",
            "        value: -0.0718927309\n",
            "        value: -0.684942424\n",
            "        value: 0.138405263\n",
            "        value: -0.0908011422\n",
            "        value: 0.230152458\n",
            "        value: 0.878610313\n",
            "        value: 0.325529277\n",
            "        value: -0.628215671\n",
            "        value: -0.176356077\n",
            "        value: -0.202440426\n",
            "        value: -1.33912814\n",
            "        value: -0.162725583\n",
            "        value: -0.121069692\n",
            "        value: 0.693622589\n",
            "        value: 0.337474167\n",
            "        value: -1.51453304\n",
            "        value: 1.08280396\n",
            "        value: -0.00943194516\n",
            "        value: -0.906413674\n",
            "        value: -0.306953967\n",
            "        value: -0.462256134\n",
            "        value: -0.322873324\n",
            "        value: 0.229023755\n",
            "        value: -0.986159801\n",
            "        value: -0.446021825\n",
            "        value: 0.23313649\n",
            "        value: -0.0926502347\n",
            "        value: 0.0384801477\n",
            "        value: 0.524299\n",
            "        value: -1.42024434\n",
            "        value: 0.86060977\n",
            "        value: -0.12567082\n",
            "        value: 0.950535655\n",
            "        value: -0.400582463\n",
            "        value: -0.40742135\n",
            "        value: 0.324405104\n",
            "        value: -1.3687464\n",
            "        value: 1.758196\n",
            "        value: 0.99127835\n",
            "        value: 0.0368830115\n",
            "        value: -0.79716897\n",
            "        value: -0.37620917\n",
            "        value: 0.60198164\n",
            "        value: 0.82203573\n",
            "        value: 1.25474143\n",
            "        value: 0.346868068\n",
            "        value: 0.607523322\n",
            "        value: -0.21188\n",
            "        value: -0.610013366\n",
            "        value: 0.166138485\n",
            "        value: 0.665833533\n",
            "        value: -0.534517884\n",
            "        value: -0.809742212\n",
            "        value: -0.595644355\n",
            "        value: 0.318049222\n",
            "        value: -0.18845287\n",
            "        value: -0.695699215\n",
            "        value: 0.308847785\n",
            "        value: 0.551494777\n",
            "        value: 0.0387006029\n",
            "        value: 0.484866679\n",
            "        value: -0.207989857\n",
            "        value: 0.00739517808\n",
            "        value: -0.775788784\n",
            "        value: 0.240041643\n",
            "        value: -0.992515504\n",
            "        value: 0.03827684\n",
            "        value: -0.0732616931\n",
            "        value: 0.134175882\n",
            "        value: 0.0414680429\n",
            "        value: -1.16528499\n",
            "        value: -0.000617753714\n",
            "        value: -0.064487949\n",
            "        value: -0.071182251\n",
            "        value: 1.12789035\n",
            "        value: -0.407363534\n",
            "        value: -0.562607467\n",
            "        value: 0.896037817\n",
            "        value: 0.215698168\n",
            "        value: 0.108136564\n",
            "        value: 0.328590125\n",
            "        value: -0.809620619\n",
            "        value: -0.34348309\n",
            "        value: 0.245763913\n",
            "        value: -0.296640962\n",
            "        value: -0.360542655\n",
            "        value: 0.528272\n",
            "        value: 0.740406871\n",
            "        value: -0.577905476\n",
            "        value: 0.621411324\n",
            "        value: -0.838806748\n",
            "        value: -0.0654297918\n",
            "        value: -0.182403505\n",
            "        value: -0.41031298\n",
            "        value: 0.314888924\n",
            "        value: -0.717176318\n",
            "        value: -0.970064521\n",
            "        value: -0.0706632957\n",
            "        value: 0.466698647\n",
            "        value: 0.0609516948\n",
            "        value: -0.974662721\n",
            "        value: 0.548814893\n",
            "        value: -0.318901688\n",
            "        value: -1.22865558\n",
            "        value: -0.6284495\n",
            "        value: -0.192321703\n",
            "        value: 0.604643345\n",
            "        value: -0.170487463\n",
            "        value: 0.458071053\n",
            "        value: -0.973865\n",
            "        value: 0.88158977\n",
            "        value: 1.13840306\n",
            "        value: 0.47981286\n",
            "        value: -0.115439937\n",
            "        value: -0.0340408236\n",
            "        value: 2.7729075\n",
            "        value: 0.709662\n",
            "        value: -1.19011867\n",
            "        value: 0.29043594\n",
            "        value: -0.232523\n",
            "        value: 0.224612847\n",
            "        value: 1.31621921\n",
            "        value: -0.610408902\n",
            "        value: 0.61268574\n",
            "        value: -0.765245557\n",
            "        value: -0.639256299\n",
            "        value: 0.765610158\n",
            "        value: 1.07594252\n",
            "        value: -0.0546719506\n",
            "        value: -0.163371533\n",
            "        value: 0.218373865\n",
            "        value: 0.433311522\n",
            "        value: 0.255957842\n",
            "        value: -0.571451545\n",
            "        value: -0.74403882\n",
            "        value: 0.0114954039\n",
            "        value: 0.0640572\n",
            "        value: -0.274313658\n",
            "        value: 0.721194863\n",
            "        value: 0.13399747\n",
            "        value: 0.258644313\n",
            "        value: -0.122067355\n",
            "        value: 0.340739816\n",
            "        value: -0.136443242\n",
            "        value: 0.406198055\n",
            "        value: 0.735901237\n",
            "        value: 1.13921642\n",
            "        value: -0.0649481565\n",
            "        value: 0.382462144\n",
            "        value: -0.411331654\n",
            "        value: 0.237717062\n",
            "        value: -1.58137143\n",
            "        value: -0.637390137\n",
            "        value: -0.204865873\n",
            "        value: -0.0678071529\n",
            "        value: 0.0300593432\n",
            "        value: 0.520526826\n",
            "        value: -0.391056091\n",
            "        value: -0.318719864\n",
            "        value: 1.33073\n",
            "        value: -0.69531\n",
            "        value: 0.00911939703\n",
            "        value: -0.285035\n",
            "        value: 0.250679076\n",
            "        value: -0.125563279\n",
            "        value: -0.043643482\n",
            "        value: -1.87630558\n",
            "        value: -0.1092498\n",
            "        value: -0.843551517\n",
            "        value: 0.731215596\n",
            "        value: -0.00383277237\n",
            "        value: -1.08774734\n",
            "        value: 0.293299317\n",
            "        value: -0.57944423\n",
            "        value: -0.0678175539\n",
            "        value: -1.42416847\n",
            "        value: 0.383633554\n",
            "        value: 0.694948733\n",
            "        value: -0.601214349\n",
            "        value: -0.330631465\n",
            "        value: 0.998119891\n",
            "        value: -0.0300507024\n",
            "        value: 0.653006315\n",
            "        value: 1.12705338\n",
            "        value: -0.0349545404\n",
            "        value: -1.06590176\n",
            "        value: -0.362306923\n",
            "        value: 0.444524467\n",
            "        value: 0.549384236\n",
            "        value: -1.0884614\n",
            "        value: -1.25754619\n",
            "        value: -0.0911777169\n",
            "        value: -0.634196103\n",
            "        value: 0.730851233\n",
            "        value: 1.69542027\n",
            "        value: 0.650710464\n",
            "        value: 0.387916803\n",
            "        value: -0.66511631\n",
            "        value: 0.0964274332\n",
            "        value: -0.592587054\n",
            "        value: 1.05962682\n",
            "        value: -1.30426157\n",
            "        value: 0.413610518\n",
            "        value: 0.705918193\n",
            "        value: 0.97088629\n",
            "        value: 0.0227895677\n",
            "        value: -0.219000414\n",
            "        value: 0.0360010788\n",
            "        value: -0.742195129\n",
            "        value: 1.46134365\n",
            "        value: -0.292801559\n",
            "        value: -0.234463528\n",
            "        value: 0.464316279\n",
            "        value: 0.189326391\n",
            "        value: 0.173043057\n",
            "        value: -0.234752551\n",
            "        value: -0.757316113\n",
            "        value: 1.9192102\n",
            "        value: 0.218817338\n",
            "        value: 0.928540945\n",
            "        value: -0.300191343\n",
            "        value: -0.740006566\n",
            "        value: 0.617590189\n",
            "        value: -0.0219087079\n",
            "        value: 0.373488456\n",
            "        value: 0.835045934\n",
            "        value: 0.868282318\n",
            "        value: -0.776178777\n",
            "        value: -0.965449214\n",
            "        value: -0.264455497\n",
            "        value: 1.80911756\n",
            "        value: 0.410665303\n",
            "        value: 0.825884759\n",
            "        value: -0.484424144\n",
            "        value: -0.655240655\n",
            "        value: 1.03608322\n",
            "        value: 0.429120332\n",
            "        value: 0.94972986\n",
            "        value: -0.2096975\n",
            "        value: 0.356108487\n",
            "        value: 0.370551944\n",
            "        value: -1.63676977\n",
            "        value: 0.28363061\n",
            "        value: 0.0171523541\n",
            "        value: 0.190559223\n",
            "        value: -0.6322577\n",
            "        value: -0.518244207\n",
            "        value: 1.05437064\n",
            "        value: 0.898689449\n",
            "        value: 0.849793792\n",
            "        value: 0.247698188\n",
            "        value: -0.524002671\n",
            "        value: -0.574294\n",
            "        value: -0.316882\n",
            "        value: -0.076219067\n",
            "        value: -0.449690342\n",
            "        value: -0.0416696668\n",
            "        value: -0.297785521\n",
            "        value: 0.56112957\n",
            "        value: 0.898653865\n",
            "        value: 0.840398431\n",
            "        value: -0.0457829088\n",
            "        value: 0.513112068\n",
            "        value: 0.597288132\n",
            "        value: 0.0237220675\n",
            "        value: 1.00272381\n",
            "        value: -0.259576857\n",
            "        value: -0.161547944\n",
            "        value: -0.74117583\n",
            "        value: 0.923614204\n",
            "        value: -0.521607101\n",
            "        value: 1.50454259\n",
            "        value: 0.195249528\n",
            "        value: -0.332568288\n",
            "        value: 0.0451568365\n",
            "        value: -0.36549139\n",
            "        value: 0.0775425583\n",
            "        value: -0.996869743\n",
            "        value: 0.304623961\n",
            "        value: 0.656890631\n",
            "        value: -1.05267096\n",
            "        value: 0.34874475\n",
            "        value: 0.364535809\n",
            "        value: -0.0579780862\n",
            "        value: -0.927225\n",
            "        value: 0.076649636\n",
            "        value: 0.14520511\n",
            "        value: -0.604083717\n",
            "        value: -1.43396378\n",
            "        value: 0.381647736\n",
            "        value: -0.613687277\n",
            "        value: 0.80088383\n",
            "        value: 0.859048426\n",
            "        value: -0.213845089\n",
            "        value: 0.244924426\n",
            "        value: 0.573134303\n",
            "        value: 0.13154456\n",
            "        value: -0.877097487\n",
            "        value: 0.176496685\n",
            "        value: -0.622454\n",
            "        value: -0.347270787\n",
            "        value: -0.319180369\n",
            "        value: -0.0907230377\n",
            "        value: -0.34127295\n",
            "        value: 1.34556603\n",
            "        value: -0.414413482\n",
            "        value: 0.0196706355\n",
            "        value: -1.09426141\n",
            "        value: -0.0539034605\n",
            "        value: 0.50950551\n",
            "        value: -0.569913864\n",
            "        value: 0.420310795\n",
            "        value: -0.512064457\n",
            "        value: 0.502276063\n",
            "        value: 0.0589524209\n",
            "        value: 0.0672073141\n",
            "        value: 0.0655321181\n",
            "        value: -0.102487981\n",
            "        value: 0.748527884\n",
            "        value: -0.827157259\n",
            "        value: -1.08208716\n",
            "        value: 0.208491161\n",
            "        value: 1.35393596\n",
            "        value: -0.792995393\n",
            "        value: -0.318920404\n",
            "        value: 0.747919559\n",
            "        value: 0.45971632\n",
            "        value: -0.336388499\n",
            "        value: 0.206014127\n",
            "        value: -1.12894726\n",
            "        value: -0.280737817\n",
            "        value: 0.487212837\n",
            "        value: 0.345356613\n",
            "        value: -0.534449875\n",
            "        value: 0.456792444\n",
            "        value: -0.612773478\n",
            "        value: -0.413206697\n",
            "        value: 0.600371242\n",
            "        value: -0.202267081\n",
            "        value: -0.766667724\n",
            "        value: 0.623154402\n",
            "        value: -1.09905183\n",
            "        value: -0.371559203\n",
            "        value: -0.639678836\n",
            "        value: -0.813055754\n",
            "        value: -0.306910515\n",
            "        value: -0.0421989486\n",
            "        value: -0.39545238\n",
            "        value: -0.237392306\n",
            "        value: 0.0290754959\n",
            "        value: -0.0241855904\n",
            "        value: -0.382882386\n",
            "        value: -0.0511995405\n",
            "        value: 0.362781554\n",
            "        value: -0.484541118\n",
            "        value: 0.52618891\n",
            "        value: -0.720159948\n",
            "        value: -0.164719403\n",
            "        value: 0.269977719\n",
            "        value: 0.41595158\n",
            "        value: 0.917387545\n",
            "        value: -0.191890553\n",
            "        value: -0.477166116\n",
            "        value: -0.529115915\n",
            "        value: -0.457078397\n",
            "        value: -0.912667453\n",
            "        value: 0.0579707026\n",
            "        value: -0.004594706\n",
            "        value: -1.13217926\n",
            "        value: -2.70291352\n",
            "        value: -0.0814298391\n",
            "        value: 0.533653378\n",
            "        value: 0.211399257\n",
            "        value: -0.5394665\n",
            "        value: -0.173815548\n",
            "        value: 0.835637212\n",
            "        value: -0.0463059135\n",
            "        value: -0.189004645\n",
            "        value: -0.204853117\n",
            "        value: -1.03547192\n",
            "        value: -2.53873754\n",
            "        value: -0.29013294\n",
            "        value: -0.653003097\n",
            "        value: -0.952444911\n",
            "        value: 1.00625944\n",
            "        value: 0.167916417\n",
            "        value: 0.575801492\n",
            "        value: -0.283101588\n",
            "        value: 1.35694337\n",
            "        value: 0.120825417\n",
            "        value: 0.568754256\n",
            "        value: 0.052074939\n",
            "        value: -1.22603917\n",
            "        value: 1.03635967\n",
            "        value: -0.476730585\n",
            "        value: -0.365540415\n",
            "        value: -0.0929895639\n",
            "        value: -0.654320061\n",
            "        value: -0.162097946\n",
            "        value: -0.71219939\n",
            "        value: -0.688324\n",
            "        value: 0.376708686\n",
            "        value: 1.00322354\n",
            "        value: -0.187958643\n",
            "        value: -0.915488243\n",
            "        value: 0.442565084\n",
            "        value: -0.25716421\n",
            "        value: 0.888689399\n",
            "        value: -0.0483770519\n",
            "        value: -0.32320109\n",
            "        value: -0.825591624\n",
            "        value: 0.136970043\n",
            "        value: 0.524776816\n",
            "        value: -1.20464873\n",
            "        value: 0.700855494\n",
            "        value: -0.651221693\n",
            "        value: 0.290947735\n",
            "        value: 1.26513445\n",
            "        value: -0.784605\n",
            "        value: 0.592513502\n",
            "        value: 0.656315923\n",
            "        value: -0.968101144\n",
            "        value: -1.37637174\n",
            "        value: -0.201256081\n",
            "        value: 0.408109754\n",
            "        value: 0.57005167\n",
            "        value: -0.582685947\n",
            "        value: -0.323567331\n",
            "        value: -0.336267322\n",
            "        value: -0.0356748402\n",
            "        value: 0.0230200663\n",
            "        value: 0.441251904\n",
            "        value: -0.779974639\n",
            "        value: 0.461351573\n",
            "        value: 0.18364346\n",
            "        value: 0.466261148\n",
            "        value: -0.149342805\n",
            "        value: -0.107908793\n",
            "        value: 0.22094807\n",
            "        value: 1.1830864\n",
            "        value: 0.943260908\n",
            "        value: 0.493229508\n",
            "        value: -0.358962357\n",
            "        value: -1.00765634\n",
            "        value: 0.353533447\n",
            "        value: -0.581719816\n",
            "        value: 0.798076928\n",
            "        value: -0.150157303\n",
            "        value: 0.554056525\n",
            "        value: -0.836259604\n",
            "        value: -1.27037215\n",
            "        value: 0.551979601\n",
            "        value: -1.26860833\n",
            "        value: -0.0486472622\n",
            "        value: 2.21739626\n",
            "        value: 1.22339439\n",
            "        value: -0.942219555\n",
            "        value: 0.541366816\n",
            "        value: 0.9479388\n",
            "        value: -0.586889267\n",
            "        value: 0.29665187\n",
            "        value: 0.255884707\n",
            "        value: 0.0508180782\n",
            "        value: 1.00297785\n",
            "        value: -0.459810406\n",
            "        value: 0.0821529329\n",
            "        value: -0.609172344\n",
            "        value: 0.60834229\n",
            "        value: 0.620572\n",
            "        value: 0.48554\n",
            "        value: -0.4766213\n",
            "        value: 0.232622758\n",
            "        value: -0.811784387\n",
            "        value: 0.0208473485\n",
            "        value: -0.873788416\n",
            "        value: 0.117583349\n",
            "        value: 1.59036613\n",
            "        value: -0.486119747\n",
            "        value: -0.539171517\n",
            "        value: 0.169911206\n",
            "        value: 0.789749\n",
            "        value: 0.617749572\n",
            "        value: 0.846725702\n",
            "        value: -0.349571139\n",
            "        value: -1.26512575\n",
            "        value: 0.868913531\n",
            "        value: 1.84108853\n",
            "        value: -0.540936112\n",
            "        value: 0.164938182\n",
            "        value: 0.723912477\n",
            "        value: -0.0837550089\n",
            "        value: 1.44663274\n",
            "        value: 0.931527615\n",
            "        value: 0.713956714\n",
            "        value: 0.701410532\n",
            "        value: -0.401362777\n",
            "        value: 0.0637173504\n",
            "        value: -1.8237375\n",
            "        value: -0.944358885\n",
            "        value: 0.818178177\n",
            "        value: 0.168697536\n",
            "        value: -0.368004799\n",
            "        value: 0.687233806\n",
            "        value: 0.189024985\n",
            "        value: -0.130359918\n",
            "        value: -0.67310822\n",
            "        value: 1.07575631\n",
            "        value: -0.743203163\n",
            "        value: 0.162647039\n",
            "        value: 0.974027514\n",
            "        value: 0.685424566\n",
            "        value: 0.236745641\n",
            "        value: 0.201944217\n",
            "        value: 0.0463644862\n",
            "        value: -0.373002768\n",
            "        value: 0.162558839\n",
            "        value: 0.102633923\n",
            "        value: -0.85998261\n",
            "        value: -0.268973827\n",
            "        value: 0.853978872\n",
            "        value: -0.359283\n",
            "        value: 1.74525571\n",
            "        value: -0.348245621\n",
            "        value: 0.0591474175\n",
            "        value: -0.714100838\n",
            "        value: 0.0728576109\n",
            "        value: -0.865254939\n",
            "        value: 0.280400038\n",
            "        value: -0.0614765286\n",
            "        value: -0.468245685\n",
            "        value: 0.482629776\n",
            "        value: -0.694622934\n",
            "        value: 2.49577427\n",
            "        value: -0.458687723\n",
            "        value: -0.109549783\n",
            "        value: -1.77147043\n",
            "        value: 0.650846601\n",
            "        value: -0.623468339\n",
            "        value: -0.261146635\n",
            "        value: 0.880119205\n",
            "        value: 0.295044214\n",
            "        value: 0.2937451\n",
            "        value: -0.698342502\n",
            "        value: -0.571182132\n",
            "        value: -0.486514151\n",
            "        value: 0.360244751\n",
            "        value: 2.38282323\n",
            "        value: -0.501368105\n",
            "        value: -0.631609499\n",
            "        value: 0.490489662\n",
            "        value: -0.232718289\n",
            "        value: -1.0233618\n",
            "        value: 0.061147891\n",
            "        value: 0.0967777371\n",
            "        value: -0.549657404\n",
            "        value: -0.0621393397\n",
            "        value: -0.261134356\n",
            "        value: 1.05004406\n",
            "        value: -0.295877635\n",
            "        value: -0.759308934\n",
            "        value: 0.107755259\n",
            "        value: -0.82773912\n",
            "        value: 1.4438138\n",
            "        value: 0.143334717\n",
            "        value: 0.7564255\n",
            "        value: -0.662278175\n",
            "        value: 0.450399965\n",
            "        value: 0.69862\n",
            "        value: 0.340454429\n",
            "        value: 0.63026756\n",
            "        value: -0.405870318\n",
            "        value: -0.0866925865\n",
            "        value: -0.627687812\n",
            "        value: -0.545592427\n",
            "        value: 0.275067985\n",
            "        value: -0.518144488\n",
            "        value: -0.0112181455\n",
            "        value: -0.226782486\n",
            "        value: -0.98592478\n",
            "        value: 0.772793353\n",
            "        value: 0.67294544\n",
            "        value: 0.661048174\n",
            "        value: 0.508782804\n",
            "        value: 1.75730467\n",
            "        value: -0.407071114\n",
            "        value: 0.264599741\n",
            "        value: -1.48657823\n",
            "        value: -1.92941797\n",
            "        value: 0.180387676\n",
            "        value: -0.504726768\n",
            "        value: -0.501179874\n",
            "        value: 0.541948795\n",
            "        value: 0.343816\n",
            "        value: 1.08870971\n",
            "        value: -1.30818248\n",
            "        value: -1.04613483\n",
            "        value: -0.568869352\n",
            "        value: -1.1110152\n",
            "        value: 0.479961038\n",
            "        value: 2.01632833\n",
            "        value: 0.403139234\n",
            "        value: 0.283670932\n",
            "        value: -0.215163961\n",
            "        value: 1.99219275\n",
            "        value: -0.770447612\n",
            "        value: -0.351142257\n",
            "        value: 0.722725868\n",
            "        value: 0.594615757\n",
            "        value: 0.9993366\n",
            "        value: 0.453751087\n",
            "        value: 0.0717555135\n",
            "        value: -0.769440472\n",
            "        value: 2.03763413\n",
            "        value: 0.0272614583\n",
            "        value: 0.700541615\n",
            "        value: -0.528103709\n",
            "        value: 0.359089375\n",
            "        value: -0.427283555\n",
            "        value: -0.17733717\n",
            "        value: 0.321575552\n",
            "        value: 1.86270499\n",
            "        value: -0.59241879\n",
            "        value: 0.0491788462\n",
            "        value: -0.122082107\n",
            "        value: -1.02910924\n",
            "        value: -0.217694551\n",
            "        value: 1.0718168\n",
            "        value: 0.344068676\n",
            "        value: -0.304902405\n",
            "        value: 1.13155913\n",
            "        value: -0.183342457\n",
            "        value: 0.649739385\n",
            "        value: -0.49909848\n",
            "        value: 0.272996187\n",
            "        value: 0.89587158\n",
            "        value: 0.572696626\n",
            "        value: -0.0883814543\n",
            "        value: -0.0736056492\n",
            "        value: 0.933802962\n",
            "        value: -0.303225845\n",
            "        value: -0.566911042\n",
            "        value: 0.767406225\n",
            "        value: -0.638934851\n",
            "        value: -0.89216274\n",
            "        value: -0.317350268\n",
            "        value: -0.00980515778\n",
            "        value: 0.198237598\n",
            "        value: 0.929518\n",
            "        value: 0.274703711\n",
            "        value: 1.49358356\n",
            "        value: 0.0221629739\n",
            "        value: 0.0982643068\n",
            "        value: 2.09074688\n",
            "        value: -0.708293378\n",
            "        value: 1.06590021\n",
            "        value: 0.413915575\n",
            "        value: 0.0307711959\n",
            "        value: -0.975500524\n",
            "        value: -1.84799111\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inspect the TFRecord file to check available features\n",
        "raw_dataset = tf.data.TFRecordDataset('/content/drive/MyDrive/client_features/client_1.tfrecord')\n",
        "\n",
        "for raw_record in raw_dataset.take(1):\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(raw_record.numpy())\n",
        "    print(example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-1pNIyuUxcZ"
      },
      "outputs": [],
      "source": [
        "def parse_tfrecord(serialized_example):\n",
        "    feature_description = {\n",
        "        'features': tf.io.FixedLenFeature([128], tf.float32),  # Update with correct name and size\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "    return example['features'], example['label']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAJq2WdPlBGF",
        "outputId": "3beedaa8-bd2f-4986-a7a5-0ef6d27f5050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Determined FEATURE_DIM: 1024\n",
            "Round 1, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.15458207), ('loss', 2.5983255), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 2, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.17371601), ('loss', 2.4475455), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 3, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.19687815), ('loss', 2.3288174), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 4, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.21903323), ('loss', 2.2293246), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 5, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.24546827), ('loss', 2.1451666), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 6, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.26183283), ('loss', 2.0704648), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 7, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.28071502), ('loss', 2.0055788), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 8, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.30589125), ('loss', 1.9472226), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 9, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.3282981), ('loss', 1.8938018), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 10, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.35196376), ('loss', 1.8442938), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 11, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.37059417), ('loss', 1.7981927), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 12, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.38695872), ('loss', 1.7552639), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 13, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.40156093), ('loss', 1.715005), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 14, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.41691843), ('loss', 1.6768906), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 15, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.43076536), ('loss', 1.6412005), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 16, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.4486405), ('loss', 1.6075383), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 17, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.46022156), ('loss', 1.5760282), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 18, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.4725579), ('loss', 1.5459279), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 19, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.48564956), ('loss', 1.5173743), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 20, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.49823767), ('loss', 1.490066), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 21, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.50956696), ('loss', 1.4641504), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 22, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5171198), ('loss', 1.4390403), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 23, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.52895266), ('loss', 1.4153948), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 24, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5375126), ('loss', 1.3921946), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 25, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5445619), ('loss', 1.370428), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 26, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.55236655), ('loss', 1.3494692), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 27, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5589124), ('loss', 1.32923), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 28, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5687311), ('loss', 1.309605), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 29, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.57477343), ('loss', 1.290862), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 30, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5820745), ('loss', 1.272914), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "# Step 1: Determine FEATURE_DIM automatically from TFRecord\n",
        "def parse_tfrecord_for_dim(serialized_example):\n",
        "    feature_description = {\n",
        "        'features': tf.io.VarLenFeature(tf.float32),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "    feature = tf.sparse.to_dense(example['features'])\n",
        "    return feature, example['label']\n",
        "\n",
        "raw_dataset = tf.data.TFRecordDataset('/content/drive/MyDrive/client_features/client_1.tfrecord')\n",
        "for raw_record in raw_dataset.take(1):\n",
        "    feature, label = parse_tfrecord_for_dim(raw_record)\n",
        "    FEATURE_DIM = feature.shape[0]\n",
        "    print(\"Determined FEATURE_DIM:\", FEATURE_DIM)\n",
        "    break\n",
        "\n",
        "# Step 2: Define the parse function with determined FEATURE_DIM\n",
        "def parse_tfrecord(serialized_example):\n",
        "    feature_description = {\n",
        "        'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.float32),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "    return example['features'], example['label']\n",
        "\n",
        "# Step 3: Load data for a specific client\n",
        "def load_data_from_tfrecord(file_path, batch_size=32):\n",
        "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
        "    dataset = raw_dataset.map(parse_tfrecord)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "# Step 4: Define ConvNeXt-inspired model\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "NUM_CLASSES = 8  # Number of classes for classification\n",
        "\n",
        "def create_convnext_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(FEATURE_DIM,)),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 5: Define model_fn using TFF's tff.learning.Model\n",
        "def model_fn():\n",
        "    keras_model = create_convnext_model()\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    input_spec = (\n",
        "        tf.TensorSpec(shape=(None, FEATURE_DIM), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.int64)\n",
        "    )\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model=keras_model,\n",
        "        input_spec=input_spec,\n",
        "        loss=loss,\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "# Step 6: Load federated data for each client\n",
        "client_1_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_1.tfrecord')\n",
        "client_2_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_2.tfrecord')\n",
        "client_3_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_3.tfrecord')\n",
        "\n",
        "# Create federated data list\n",
        "federated_data = [client_1_data, client_2_data, client_3_data]\n",
        "\n",
        "# Step 7: Define the Federated Averaging process with client optimizer\n",
        "# Define TFF-compatible optimizers\n",
        "# Call the functions to get optimizer objects instead of passing the functions themselves\n",
        "client_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=0.001)\n",
        "server_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=1.0)\n",
        "\n",
        "# Define federated training process\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=model_fn,\n",
        "    client_optimizer_fn=client_optimizer_fn,  # Pass the optimizer object\n",
        "    server_optimizer_fn=server_optimizer_fn  # Pass the optimizer object\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize the federated process state\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "# Step 8: Training loop\n",
        "NUM_ROUNDS = 30  # Define the number of federated training rounds\n",
        "for round_num in range(1, NUM_ROUNDS + 1):\n",
        "    state, metrics = iterative_process.next(state, federated_data)\n",
        "    print(f'Round {round_num}, Metrics={metrics}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJd0t_WavCtf",
        "outputId": "877e0f46-c619-4cfe-bf89-5bd37de68cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Determined FEATURE_DIM: 1024\n",
            "Round 1, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.14929506), ('loss', 2.5990252), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 2, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1644008), ('loss', 2.4336286), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 3, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1905841), ('loss', 2.307085), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 4, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.21752267), ('loss', 2.206405), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 5, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.23841894), ('loss', 2.1223965), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 6, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.26359516), ('loss', 2.0501087), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 7, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.28726083), ('loss', 1.9849441), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 8, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.30589125), ('loss', 1.9262083), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 9, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.33257803), ('loss', 1.8721684), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 10, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.3481873), ('loss', 1.8227502), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 11, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.36706948), ('loss', 1.7771802), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 12, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.38620344), ('loss', 1.7346501), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 13, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.4043303), ('loss', 1.6944132), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 14, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.42145014), ('loss', 1.6562291), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 15, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.43554884), ('loss', 1.620746), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 16, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.45266867), ('loss', 1.5880476), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 17, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.46928498), ('loss', 1.5566237), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 18, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.48086607), ('loss', 1.5267631), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 19, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.48917422), ('loss', 1.4985199), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 20, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5007553), ('loss', 1.4715172), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 21, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.51057404), ('loss', 1.4455738), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 22, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5226586), ('loss', 1.4206216), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 23, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5347432), ('loss', 1.397031), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 24, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5440584), ('loss', 1.3740681), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 25, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.55337363), ('loss', 1.3518497), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 26, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.56168175), ('loss', 1.3314873), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 27, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5707452), ('loss', 1.3106538), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 28, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.57980865), ('loss', 1.2908418), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 29, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.58912385), ('loss', 1.2716019), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 30, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.596425), ('loss', 1.2536441), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 31, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.59994966), ('loss', 1.2363869), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 32, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6047331), ('loss', 1.2192234), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 33, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6077543), ('loss', 1.2030113), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 34, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6135448), ('loss', 1.1871523), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 35, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6195871), ('loss', 1.1717588), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 36, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6251259), ('loss', 1.1567787), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 37, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.62940586), ('loss', 1.1426091), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 38, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.63343406), ('loss', 1.1288555), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 39, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.63796574), ('loss', 1.1154317), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 40, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.63997984), ('loss', 1.1025039), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 41, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.64274925), ('loss', 1.090198), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 42, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6452669), ('loss', 1.0781685), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 43, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.65080565), ('loss', 1.0667646), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 44, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.653575), ('loss', 1.0554292), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 45, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6583585), ('loss', 1.0445764), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 46, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6596173), ('loss', 1.0335786), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 47, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6623867), ('loss', 1.0233474), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 48, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6659114), ('loss', 1.0132333), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 49, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.66943604), ('loss', 1.0037905), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 50, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6717019), ('loss', 0.9941802), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 51, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6764854), ('loss', 0.98481226), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 52, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6784995), ('loss', 0.9759048), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 53, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6817724), ('loss', 0.9669857), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 54, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.683283), ('loss', 0.9586065), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 55, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6870594), ('loss', 0.9500169), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 56, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.69058406), ('loss', 0.94197124), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 57, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.69360524), ('loss', 0.9339795), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 58, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6958711), ('loss', 0.9260238), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 59, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6993958), ('loss', 0.91805), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 60, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7019134), ('loss', 0.9108342), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 61, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7024169), ('loss', 0.90322894), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 62, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7054381), ('loss', 0.8960079), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 63, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.70871097), ('loss', 0.8888842), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 64, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.71198386), ('loss', 0.88195115), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 65, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7145015), ('loss', 0.87524635), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 66, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7165156), ('loss', 0.86890864), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 67, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.72029203), ('loss', 0.86215115), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 68, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7218026), ('loss', 0.85582024), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 69, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.72306144), ('loss', 0.8492672), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 70, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.72608256), ('loss', 0.8433886), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 71, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7278449), ('loss', 0.83719665), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 72, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7306143), ('loss', 0.8312863), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 73, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7328802), ('loss', 0.82535), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 74, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.73413897), ('loss', 0.81943357), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 75, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.73539776), ('loss', 0.81372786), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 76, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7396777), ('loss', 0.8081438), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 77, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7416918), ('loss', 0.8026654), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 78, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.74345416), ('loss', 0.79680836), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 79, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.74446124), ('loss', 0.7912326), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 80, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.74546826), ('loss', 0.7859788), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 81, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.74622357), ('loss', 0.78063303), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 82, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7477341), ('loss', 0.775563), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 83, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75025177), ('loss', 0.77055), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 84, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7527694), ('loss', 0.7651917), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 85, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75352466), ('loss', 0.7598582), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 86, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7550352), ('loss', 0.75483024), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 87, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7570493), ('loss', 0.75010145), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 88, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7573011), ('loss', 0.74494314), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 89, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7603223), ('loss', 0.74045366), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 90, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.76158106), ('loss', 0.7354772), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 91, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7640987), ('loss', 0.73079044), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 92, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7666163), ('loss', 0.72614676), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 93, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7681269), ('loss', 0.7215229), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 94, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.77089626), ('loss', 0.7169401), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 95, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7724069), ('loss', 0.7122887), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 96, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.77366567), ('loss', 0.7078417), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 97, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.775428), ('loss', 0.7030993), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 98, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.77693856), ('loss', 0.699042), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 99, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7787009), ('loss', 0.69434226), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 100, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.78096676), ('loss', 0.6900683), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "# Step 1: Determine FEATURE_DIM automatically from TFRecord\n",
        "def parse_tfrecord_for_dim(serialized_example):\n",
        "    feature_description = {\n",
        "        'features': tf.io.VarLenFeature(tf.float32),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "    feature = tf.sparse.to_dense(example['features'])\n",
        "    return feature, example['label']\n",
        "\n",
        "raw_dataset = tf.data.TFRecordDataset('/content/drive/MyDrive/client_features/client_1.tfrecord')\n",
        "for raw_record in raw_dataset.take(1):\n",
        "    feature, label = parse_tfrecord_for_dim(raw_record)\n",
        "    FEATURE_DIM = feature.shape[0]\n",
        "    print(\"Determined FEATURE_DIM:\", FEATURE_DIM)\n",
        "    break\n",
        "\n",
        "# Step 2: Define the parse function with determined FEATURE_DIM\n",
        "def parse_tfrecord(serialized_example):\n",
        "    feature_description = {\n",
        "        'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.float32),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "    return example['features'], example['label']\n",
        "\n",
        "# Step 3: Load data for a specific client\n",
        "def load_data_from_tfrecord(file_path, batch_size=32):\n",
        "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
        "    dataset = raw_dataset.map(parse_tfrecord)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "# Step 4: Define ConvNeXt-inspired model\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "NUM_CLASSES = 7  # Number of classes for classification\n",
        "\n",
        "def create_convnext_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(FEATURE_DIM,)),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 5: Define model_fn using TFF's tff.learning.Model\n",
        "def model_fn():\n",
        "    keras_model = create_convnext_model()\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    input_spec = (\n",
        "        tf.TensorSpec(shape=(None, FEATURE_DIM), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.int64)\n",
        "    )\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model=keras_model,\n",
        "        input_spec=input_spec,\n",
        "        loss=loss,\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "# Step 6: Load federated data for each client\n",
        "client_1_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_1.tfrecord')\n",
        "client_2_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_2.tfrecord')\n",
        "client_3_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_3.tfrecord')\n",
        "\n",
        "# Create federated data list\n",
        "federated_data = [client_1_data, client_2_data, client_3_data]\n",
        "\n",
        "# Step 7: Define the Federated Averaging process with client optimizer\n",
        "# Define TFF-compatible optimizers\n",
        "# Call the functions to get optimizer objects instead of passing the functions themselves\n",
        "client_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=0.001)\n",
        "server_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=1.0)\n",
        "\n",
        "# Define federated training process\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=model_fn,\n",
        "    client_optimizer_fn=client_optimizer_fn,  # Pass the optimizer object\n",
        "    server_optimizer_fn=server_optimizer_fn  # Pass the optimizer object\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize the federated process state\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "# Step 8: Training loop\n",
        "NUM_ROUNDS = 100  # Define the number of federated training rounds\n",
        "for round_num in range(1, NUM_ROUNDS + 1):\n",
        "    state, metrics = iterative_process.next(state, federated_data)\n",
        "    print(f'Round {round_num}, Metrics={metrics}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "# Step 1: Determine FEATURE_DIM automatically from TFRecord\n",
        "def parse_tfrecord_for_dim(serialized_example):\n",
        "    feature_description = {\n",
        "        'features': tf.io.VarLenFeature(tf.float32),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "    feature = tf.sparse.to_dense(example['features'])\n",
        "    return feature, example['label']\n",
        "\n",
        "raw_dataset = tf.data.TFRecordDataset('/content/drive/MyDrive/client_features/client_1.tfrecord')\n",
        "for raw_record in raw_dataset.take(1):\n",
        "    feature, label = parse_tfrecord_for_dim(raw_record)\n",
        "    FEATURE_DIM = feature.shape[0]\n",
        "    print(\"Determined FEATURE_DIM:\", FEATURE_DIM)\n",
        "    break\n",
        "\n",
        "# Step 2: Define the parse function with determined FEATURE_DIM\n",
        "def parse_tfrecord(serialized_example):\n",
        "    feature_description = {\n",
        "        'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.float32),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "    return example['features'], example['label']\n",
        "\n",
        "# Step 3: Load data for a specific client\n",
        "def load_data_from_tfrecord(file_path, batch_size=32):\n",
        "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
        "    dataset = raw_dataset.map(parse_tfrecord)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "# Step 4: Define ConvNeXt-inspired model\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "NUM_CLASSES = 7  # Number of classes for classification\n",
        "\n",
        "def create_convnext_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(FEATURE_DIM,)),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 5: Define model_fn using TFF's tff.learning.Model\n",
        "def model_fn():\n",
        "    keras_model = create_convnext_model()\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    input_spec = (\n",
        "        tf.TensorSpec(shape=(None, FEATURE_DIM), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.int64)\n",
        "    )\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model=keras_model,\n",
        "        input_spec=input_spec,\n",
        "        loss=loss,\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "# Step 6: Load federated data for each client\n",
        "client_1_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_1.tfrecord')\n",
        "client_2_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_2.tfrecord')\n",
        "client_3_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_3.tfrecord')\n",
        "\n",
        "# Create federated data list\n",
        "federated_data = [client_1_data, client_2_data, client_3_data]\n",
        "\n",
        "# Step 7: Define the Federated Averaging process with client optimizer\n",
        "# Define TFF-compatible optimizers\n",
        "# Call the functions to get optimizer objects instead of passing the functions themselves\n",
        "client_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=0.001)\n",
        "server_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=1.0)\n",
        "\n",
        "# Define federated training process\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=model_fn,\n",
        "    client_optimizer_fn=client_optimizer_fn,  # Pass the optimizer object\n",
        "    server_optimizer_fn=server_optimizer_fn  # Pass the optimizer object\n",
        ")\n",
        "\n",
        "\n",
        "# Initialize the federated process state\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "# Step 8: Training loop\n",
        "NUM_ROUNDS = 200  # Define the number of federated training rounds\n",
        "for round_num in range(1, NUM_ROUNDS + 1):\n",
        "    state, metrics = iterative_process.next(state, federated_data)\n",
        "    print(f'Round {round_num}, Metrics={metrics}')\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/retinal_disease_model_.h5'\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohreAL3-M1LT",
        "outputId": "a617e5e9-80e3-4a1c-8009-827ea575350a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Determined FEATURE_DIM: 1024\n",
            "Round 1, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.14602216), ('loss', 2.52971), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 2, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.17396778), ('loss', 2.342412), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 3, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1971299), ('loss', 2.205012), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 4, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.22583081), ('loss', 2.1008446), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 5, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.24572004), ('loss', 2.0152476), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 6, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.2729104), ('loss', 1.9420834), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 7, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.29556897), ('loss', 1.8770179), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 8, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.31722054), ('loss', 1.8202415), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 9, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.33761328), ('loss', 1.7674267), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 10, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.3582578), ('loss', 1.719902), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 11, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.37865055), ('loss', 1.6767303), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 12, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.39803624), ('loss', 1.6360384), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 13, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.41641492), ('loss', 1.5987134), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 14, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.43353474), ('loss', 1.564275), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 15, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.4466264), ('loss', 1.5316099), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 16, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.4619839), ('loss', 1.500363), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 17, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.47507554), ('loss', 1.4709156), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 18, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.48716012), ('loss', 1.4428618), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 19, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.49672708), ('loss', 1.4165653), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 20, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5093152), ('loss', 1.3918828), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 21, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.52190334), ('loss', 1.3681886), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 22, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.53096676), ('loss', 1.3459828), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 23, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.54128903), ('loss', 1.3243793), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 24, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.55236655), ('loss', 1.3036374), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 25, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.56117827), ('loss', 1.2839631), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 26, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5707452), ('loss', 1.2653534), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 27, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.57980865), ('loss', 1.2465088), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 28, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.58685803), ('loss', 1.2289844), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 29, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.59592146), ('loss', 1.212067), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 30, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6024673), ('loss', 1.1956474), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 31, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6077543), ('loss', 1.1798161), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 32, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6107754), ('loss', 1.16469), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 33, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.61807656), ('loss', 1.1500766), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 34, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.62462234), ('loss', 1.1355027), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 35, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.63192344), ('loss', 1.1218599), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 36, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.63796574), ('loss', 1.1082966), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 37, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.63972807), ('loss', 1.095363), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 38, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.64350456), ('loss', 1.0825415), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 39, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.647281), ('loss', 1.0702945), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 40, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6538268), ('loss', 1.0584358), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 41, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6563444), ('loss', 1.0468924), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 42, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6591138), ('loss', 1.0355433), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 43, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6636455), ('loss', 1.0245463), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 44, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6666667), ('loss', 1.0140431), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 45, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6719537), ('loss', 1.0035092), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 46, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.673716), ('loss', 0.9934336), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 47, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6769889), ('loss', 0.9838166), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 48, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6810171), ('loss', 0.97418517), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 49, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.68429005), ('loss', 0.96482605), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 50, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6878147), ('loss', 0.95576876), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 51, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.69234645), ('loss', 0.9469013), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 52, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6951158), ('loss', 0.9384173), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 53, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.69889224), ('loss', 0.92996395), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 54, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6998993), ('loss', 0.9217845), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 55, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7019134), ('loss', 0.9137199), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 56, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7041792), ('loss', 0.9057929), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 57, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.70669687), ('loss', 0.8977669), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 58, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7104733), ('loss', 0.89055324), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 59, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7134945), ('loss', 0.8827926), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 60, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.71701914), ('loss', 0.8753371), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 61, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.71802616), ('loss', 0.86817724), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 62, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.72029203), ('loss', 0.8613087), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 63, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7218026), ('loss', 0.8544076), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 64, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.72507554), ('loss', 0.8473575), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 65, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.72809666), ('loss', 0.8405006), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 66, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.73111784), ('loss', 0.834), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 67, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7333837), ('loss', 0.8276827), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 68, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.73514605), ('loss', 0.82128906), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 69, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7376636), ('loss', 0.8147112), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 70, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.74043304), ('loss', 0.8085634), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 71, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7429507), ('loss', 0.8025202), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 72, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.74546826), ('loss', 0.796405), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 73, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7459718), ('loss', 0.79064465), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 74, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7487412), ('loss', 0.78473425), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 75, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75050354), ('loss', 0.7791129), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 76, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75151056), ('loss', 0.7732723), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 77, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7522659), ('loss', 0.7676686), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 78, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75251764), ('loss', 0.76217973), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 79, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7540282), ('loss', 0.75685585), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 80, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75377643), ('loss', 0.7513651), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 81, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75780463), ('loss', 0.7461473), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 82, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.76158106), ('loss', 0.7408669), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 83, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.76283985), ('loss', 0.735824), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 84, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7661128), ('loss', 0.7308977), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 85, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.76686805), ('loss', 0.72588253), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 86, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7693857), ('loss', 0.72082895), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 87, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.76988924), ('loss', 0.71613926), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 88, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7721551), ('loss', 0.71124345), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 89, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.77366567), ('loss', 0.70618045), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 90, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.77366567), ('loss', 0.7017209), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 91, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7761833), ('loss', 0.6969954), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 92, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7771903), ('loss', 0.692344), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 93, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7787009), ('loss', 0.6879461), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 94, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.77995974), ('loss', 0.6831264), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 95, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7822256), ('loss', 0.67848426), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 96, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.78524673), ('loss', 0.6740195), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 97, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.78700906), ('loss', 0.6696194), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 98, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.78927493), ('loss', 0.6649996), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 99, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.79028195), ('loss', 0.6606602), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 100, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.79128903), ('loss', 0.6564637), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 101, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7940584), ('loss', 0.6521), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 102, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.795569), ('loss', 0.6478501), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 103, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7968278), ('loss', 0.6435439), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 104, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.79833835), ('loss', 0.63925934), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 105, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8001007), ('loss', 0.6353283), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 106, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.80135953), ('loss', 0.63110507), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 107, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8041289), ('loss', 0.62681764), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 108, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8048842), ('loss', 0.6227046), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 109, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8068983), ('loss', 0.6186127), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 110, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.80941594), ('loss', 0.6145034), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 111, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8106747), ('loss', 0.6104543), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 112, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.81319237), ('loss', 0.6067564), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 113, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.81646526), ('loss', 0.6027871), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 114, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8187311), ('loss', 0.5989489), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 115, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.820997), ('loss', 0.59507656), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 116, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.822004), ('loss', 0.59107184), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 117, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8240181), ('loss', 0.58736473), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 118, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.82578045), ('loss', 0.58362854), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 119, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.82653576), ('loss', 0.57995033), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 120, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.82779455), ('loss', 0.5764807), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 121, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.82880163), ('loss', 0.57245237), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 122, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8320745), ('loss', 0.5693435), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 123, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.83257806), ('loss', 0.56524503), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 124, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8340886), ('loss', 0.56155956), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 125, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8355992), ('loss', 0.55802757), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 126, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.83710974), ('loss', 0.55463636), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 127, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8381168), ('loss', 0.55108), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 128, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.83862036), ('loss', 0.5473972), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 129, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8413897), ('loss', 0.54405326), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 130, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8434038), ('loss', 0.54043466), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 131, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.84466267), ('loss', 0.5370203), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 132, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.846425), ('loss', 0.53352886), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 133, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8476838), ('loss', 0.5299779), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 134, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.84919435), ('loss', 0.5265372), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 135, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.84994966), ('loss', 0.5231749), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 136, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8502014), ('loss', 0.5200394), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 137, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8524673), ('loss', 0.5166238), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 138, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8544814), ('loss', 0.513173), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 139, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8549849), ('loss', 0.5098993), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 140, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8567472), ('loss', 0.50645834), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 141, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8577543), ('loss', 0.5034521), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 142, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.85850954), ('loss', 0.50010324), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 143, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.86127895), ('loss', 0.49675024), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 144, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8607754), ('loss', 0.49363148), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 145, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.86253774), ('loss', 0.49045533), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 146, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8635448), ('loss', 0.4873459), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 147, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8655589), ('loss', 0.4841532), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 148, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8655589), ('loss', 0.4810699), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 149, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.86858004), ('loss', 0.47793582), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 150, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.86933535), ('loss', 0.4747886), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 151, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.871853), ('loss', 0.47181234), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 152, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8721047), ('loss', 0.46874437), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 153, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.87260824), ('loss', 0.46588123), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 154, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8741188), ('loss', 0.46271175), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 155, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8751259), ('loss', 0.4596291), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 156, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8768882), ('loss', 0.45666805), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 157, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.878147), ('loss', 0.45370516), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 158, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8783988), ('loss', 0.45077524), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 159, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.88066465), ('loss', 0.44796288), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 160, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.88192344), ('loss', 0.4450947), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 161, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8836858), ('loss', 0.44239578), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 162, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8851964), ('loss', 0.43934086), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 163, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.88670695), ('loss', 0.4366137), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 164, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8872105), ('loss', 0.43385625), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 165, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8889728), ('loss', 0.43093997), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 166, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8889728), ('loss', 0.42823416), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 167, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8902316), ('loss', 0.42553663), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 168, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.89073515), ('loss', 0.4227917), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 169, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8924975), ('loss', 0.41997185), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 170, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.89274925), ('loss', 0.41709927), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 171, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.893001), ('loss', 0.4145312), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 172, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8942598), ('loss', 0.4119505), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 173, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8952669), ('loss', 0.40900493), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 174, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8965257), ('loss', 0.40641615), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 175, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.89677745), ('loss', 0.4037558), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 176, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8975327), ('loss', 0.4012041), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 177, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.89803624), ('loss', 0.39859882), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 178, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.89879155), ('loss', 0.3958516), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 179, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.90080565), ('loss', 0.3932866), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 180, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.90080565), ('loss', 0.3907706), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 181, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9023162), ('loss', 0.38817278), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 182, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9030715), ('loss', 0.38568747), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 183, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.90609264), ('loss', 0.38301656), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 184, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9070997), ('loss', 0.38068485), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 185, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9076032), ('loss', 0.3781217), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 186, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9091138), ('loss', 0.37576813), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 187, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.91087615), ('loss', 0.37309945), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 188, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9123867), ('loss', 0.37072238), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 189, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9136455), ('loss', 0.3682584), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 190, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.91515607), ('loss', 0.36582512), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 191, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9156596), ('loss', 0.36355287), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 192, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.91691846), ('loss', 0.36108962), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 193, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.918429), ('loss', 0.35886675), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 194, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9186808), ('loss', 0.35629785), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 195, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.92019135), ('loss', 0.3540573), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 196, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.92019135), ('loss', 0.35188788), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 197, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.92119837), ('loss', 0.3494216), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 198, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9219537), ('loss', 0.34729946), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 199, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.92220545), ('loss', 0.3448375), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 200, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.92346424), ('loss', 0.3426313), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "\n",
            "Model saved to /content/drive/MyDrive/retinal_disease_model_.h5\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "# Step 1: Determine FEATURE_DIM automatically from TFRecord\n",
        "def parse_tfrecord_for_dim(serialized_example):\n",
        "    feature_description = {\n",
        "        'features': tf.io.VarLenFeature(tf.float32),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "    feature = tf.sparse.to_dense(example['features'])\n",
        "    return feature, example['label']\n",
        "\n",
        "raw_dataset = tf.data.TFRecordDataset('/content/drive/MyDrive/client_features/client_1.tfrecord')\n",
        "for raw_record in raw_dataset.take(1):\n",
        "    feature, label = parse_tfrecord_for_dim(raw_record)\n",
        "    FEATURE_DIM = feature.shape[0]\n",
        "    print(\"Determined FEATURE_DIM:\", FEATURE_DIM)\n",
        "    break\n",
        "\n",
        "# Step 2: Define the parse function with determined FEATURE_DIM\n",
        "def parse_tfrecord(serialized_example):\n",
        "    feature_description = {\n",
        "        'features': tf.io.FixedLenFeature([FEATURE_DIM], tf.float32),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "    return example['features'], example['label']\n",
        "\n",
        "# Step 3: Load data for a specific client\n",
        "def load_data_from_tfrecord(file_path, batch_size=32):\n",
        "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
        "    dataset = raw_dataset.map(parse_tfrecord)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset\n",
        "\n",
        "# Step 4: Define ConvNeXt-inspired model\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "NUM_CLASSES = 7  # Number of classes for classification\n",
        "\n",
        "def create_convnext_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(FEATURE_DIM,)),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 5: Define model_fn using TFF's tff.learning.Model\n",
        "def model_fn():\n",
        "    keras_model = create_convnext_model()\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "    input_spec = (\n",
        "        tf.TensorSpec(shape=(None, FEATURE_DIM), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.int64)\n",
        "    )\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model=keras_model,\n",
        "        input_spec=input_spec,\n",
        "        loss=loss,\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "# Step 6: Load federated data and additional datasets\n",
        "client_1_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_1.tfrecord')\n",
        "client_2_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_2.tfrecord')\n",
        "client_3_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/client_3.tfrecord')\n",
        "\n",
        "# Federated data\n",
        "federated_data = [client_1_data, client_2_data, client_3_data]\n",
        "\n",
        "# Load validation and test datasets\n",
        "validation_data = load_data_from_tfrecord('/content/drive/MyDrive/client_features/validation.tfrecord')\n",
        "\n",
        "# Step 7: Define federated averaging process\n",
        "client_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=0.001)\n",
        "server_optimizer_fn = tff.learning.optimizers.build_sgdm(learning_rate=1.0)\n",
        "\n",
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn=model_fn,\n",
        "    client_optimizer_fn=client_optimizer_fn,\n",
        "    server_optimizer_fn=server_optimizer_fn\n",
        ")\n",
        "\n",
        "# Initialize federated process\n",
        "state = iterative_process.initialize()\n",
        "\n",
        "# Helper function to evaluate the model on a dataset\n",
        "def evaluate_model_on_dataset(model, dataset):\n",
        "    \"\"\"Evaluate a Keras model on a given dataset.\"\"\"\n",
        "    model.compile(\n",
        "        optimizer='adam',  # Optimizer doesn't matter here since we're only evaluating\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "    results = model.evaluate(dataset, verbose=0)\n",
        "    return {metric.name: result for metric, result in zip(model.metrics, results)}\n",
        "\n",
        "# Step 8: Federated training loop with validation\n",
        "NUM_ROUNDS = 200\n",
        "for round_num in range(1, NUM_ROUNDS + 1):\n",
        "    state, metrics = iterative_process.next(state, federated_data)\n",
        "\n",
        "    # Convert TFF weights to Keras model and evaluate\n",
        "    keras_model = create_convnext_model()\n",
        "    state.model_weights.assign_weights_to(keras_model)\n",
        "    val_metrics = evaluate_model_on_dataset(keras_model, validation_data)\n",
        "\n",
        "    print(f\"Round {round_num}, Training Metrics={metrics}, Validation Loss: {val_metrics['loss']}, Validation Accuracy: {val_metrics['sparse_categorical_accuracy']}\")\n",
        "\n",
        "# Step 9: Evaluate the final model on the test dataset\n",
        "keras_model = create_convnext_model()\n",
        "state.model_weights.assign_weights_to(keras_model)\n",
        "test_metrics = evaluate_model_on_dataset(keras_model, test_data)\n",
        "print(f\"Validation Loss: {validation_metrics['loss']}, Validation Accuracy: {validation_metrics['sparse_categorical_accuracy']}\")\n",
        "\n",
        "# Save the final model\n",
        "model_save_path = '/content/drive/MyDrive/retinal_disease_model.tf'\n",
        "keras_model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7kzgMigLW25",
        "outputId": "e3189887-c983-4da8-d2e0-a5676237739f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Determined FEATURE_DIM: 1024\n",
            "Round 1, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.14602216), ('loss', 2.52971), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 2, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.17396778), ('loss', 2.342412), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 3, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.1971299), ('loss', 2.205012), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 4, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.22583081), ('loss', 2.1008446), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 5, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.24572004), ('loss', 2.0152476), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 6, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.2729104), ('loss', 1.9420834), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 7, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.29556897), ('loss', 1.8770179), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 8, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.31722054), ('loss', 1.8202415), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 9, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.33761328), ('loss', 1.7674267), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 10, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.3582578), ('loss', 1.719902), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 11, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.37865055), ('loss', 1.6767303), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 12, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.39803624), ('loss', 1.6360384), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 13, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.41641492), ('loss', 1.5987134), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 14, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.43353474), ('loss', 1.564275), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 15, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.4466264), ('loss', 1.5316099), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 16, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.4619839), ('loss', 1.500363), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 17, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.47507554), ('loss', 1.4709156), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 18, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.48716012), ('loss', 1.4428618), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 19, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.49672708), ('loss', 1.4165653), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 20, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5093152), ('loss', 1.3918828), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 21, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.52190334), ('loss', 1.3681886), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 22, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.53096676), ('loss', 1.3459828), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 23, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.54128903), ('loss', 1.3243793), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 24, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.55236655), ('loss', 1.3036374), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 25, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.56117827), ('loss', 1.2839631), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 26, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.5707452), ('loss', 1.2653534), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 27, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.57980865), ('loss', 1.2465088), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 28, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.58685803), ('loss', 1.2289844), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 29, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.59592146), ('loss', 1.212067), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 30, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6024673), ('loss', 1.1956474), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 31, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6077543), ('loss', 1.1798161), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 32, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6107754), ('loss', 1.16469), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 33, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.61807656), ('loss', 1.1500766), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 34, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.62462234), ('loss', 1.1355027), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 35, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.63192344), ('loss', 1.1218599), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 36, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.63796574), ('loss', 1.1082966), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 37, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.63972807), ('loss', 1.095363), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 38, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.64350456), ('loss', 1.0825415), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 39, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.647281), ('loss', 1.0702945), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 40, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6538268), ('loss', 1.0584358), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 41, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6563444), ('loss', 1.0468924), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 42, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6591138), ('loss', 1.0355433), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 43, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6636455), ('loss', 1.0245463), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 44, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6666667), ('loss', 1.0140431), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 45, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6719537), ('loss', 1.0035092), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 46, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.673716), ('loss', 0.9934336), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 47, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6769889), ('loss', 0.9838166), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 48, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6810171), ('loss', 0.97418517), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 49, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.68429005), ('loss', 0.96482605), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 50, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6878147), ('loss', 0.95576876), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 51, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.69234645), ('loss', 0.9469013), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 52, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6951158), ('loss', 0.9384173), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 53, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.69889224), ('loss', 0.92996395), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 54, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.6998993), ('loss', 0.9217845), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 55, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7019134), ('loss', 0.9137199), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 56, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7041792), ('loss', 0.9057929), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 57, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.70669687), ('loss', 0.8977669), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 58, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7104733), ('loss', 0.89055324), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 59, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7134945), ('loss', 0.8827926), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 60, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.71701914), ('loss', 0.8753371), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 61, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.71802616), ('loss', 0.86817724), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 62, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.72029203), ('loss', 0.8613087), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 63, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7218026), ('loss', 0.8544076), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 64, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.72507554), ('loss', 0.8473575), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 65, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.72809666), ('loss', 0.8405006), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 66, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.73111784), ('loss', 0.834), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 67, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7333837), ('loss', 0.8276827), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 68, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.73514605), ('loss', 0.82128906), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 69, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7376636), ('loss', 0.8147112), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 70, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.74043304), ('loss', 0.8085634), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 71, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7429507), ('loss', 0.8025202), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 72, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.74546826), ('loss', 0.796405), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 73, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7459718), ('loss', 0.79064465), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 74, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7487412), ('loss', 0.78473425), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 75, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75050354), ('loss', 0.7791129), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 76, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75151056), ('loss', 0.7732723), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 77, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7522659), ('loss', 0.7676686), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 78, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75251764), ('loss', 0.76217973), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 79, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7540282), ('loss', 0.75685585), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 80, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75377643), ('loss', 0.7513651), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 81, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.75780463), ('loss', 0.7461473), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 82, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.76158106), ('loss', 0.7408669), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 83, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.76283985), ('loss', 0.735824), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 84, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7661128), ('loss', 0.7308977), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 85, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.76686805), ('loss', 0.72588253), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 86, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7693857), ('loss', 0.72082895), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 87, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.76988924), ('loss', 0.71613926), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 88, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7721551), ('loss', 0.71124345), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 89, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.77366567), ('loss', 0.70618045), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 90, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.77366567), ('loss', 0.7017209), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 91, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7761833), ('loss', 0.6969954), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 92, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7771903), ('loss', 0.692344), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 93, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7787009), ('loss', 0.6879461), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 94, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.77995974), ('loss', 0.6831264), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 95, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7822256), ('loss', 0.67848426), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 96, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.78524673), ('loss', 0.6740195), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 97, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.78700906), ('loss', 0.6696194), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 98, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.78927493), ('loss', 0.6649996), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 99, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.79028195), ('loss', 0.6606602), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 100, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.79128903), ('loss', 0.6564637), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 101, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7940584), ('loss', 0.6521), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 102, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.795569), ('loss', 0.6478501), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 103, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.7968278), ('loss', 0.6435439), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 104, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.79833835), ('loss', 0.63925934), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 105, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8001007), ('loss', 0.6353283), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 106, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.80135953), ('loss', 0.63110507), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 107, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8041289), ('loss', 0.62681764), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 108, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8048842), ('loss', 0.6227046), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 109, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8068983), ('loss', 0.6186127), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 110, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.80941594), ('loss', 0.6145034), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 111, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8106747), ('loss', 0.6104543), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 112, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.81319237), ('loss', 0.6067564), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 113, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.81646526), ('loss', 0.6027871), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 114, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8187311), ('loss', 0.5989489), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 115, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.820997), ('loss', 0.59507656), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 116, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.822004), ('loss', 0.59107184), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 117, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8240181), ('loss', 0.58736473), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 118, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.82578045), ('loss', 0.58362854), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 119, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.82653576), ('loss', 0.57995033), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 120, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.82779455), ('loss', 0.5764807), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 121, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.82880163), ('loss', 0.57245237), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 122, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8320745), ('loss', 0.5693435), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 123, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.83257806), ('loss', 0.56524503), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 124, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8340886), ('loss', 0.56155956), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 125, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8355992), ('loss', 0.55802757), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 126, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.83710974), ('loss', 0.55463636), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 127, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8381168), ('loss', 0.55108), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 128, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.83862036), ('loss', 0.5473972), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 129, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8413897), ('loss', 0.54405326), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 130, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8434038), ('loss', 0.54043466), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 131, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.84466267), ('loss', 0.5370203), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 132, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.846425), ('loss', 0.53352886), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 133, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8476838), ('loss', 0.5299779), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 134, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.84919435), ('loss', 0.5265372), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 135, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.84994966), ('loss', 0.5231749), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 136, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8502014), ('loss', 0.5200394), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 137, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8524673), ('loss', 0.5166238), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 138, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8544814), ('loss', 0.513173), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 139, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8549849), ('loss', 0.5098993), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 140, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8567472), ('loss', 0.50645834), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 141, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8577543), ('loss', 0.5034521), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 142, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.85850954), ('loss', 0.50010324), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 143, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.86127895), ('loss', 0.49675024), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 144, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8607754), ('loss', 0.49363148), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 145, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.86253774), ('loss', 0.49045533), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 146, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8635448), ('loss', 0.4873459), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 147, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8655589), ('loss', 0.4841532), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 148, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8655589), ('loss', 0.4810699), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 149, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.86858004), ('loss', 0.47793582), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 150, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.86933535), ('loss', 0.4747886), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 151, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.871853), ('loss', 0.47181234), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 152, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8721047), ('loss', 0.46874437), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 153, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.87260824), ('loss', 0.46588123), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 154, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8741188), ('loss', 0.46271175), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 155, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8751259), ('loss', 0.4596291), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 156, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8768882), ('loss', 0.45666805), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 157, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.878147), ('loss', 0.45370516), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 158, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8783988), ('loss', 0.45077524), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 159, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.88066465), ('loss', 0.44796288), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 160, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.88192344), ('loss', 0.4450947), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 161, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8836858), ('loss', 0.44239578), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 162, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8851964), ('loss', 0.43934086), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 163, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.88670695), ('loss', 0.4366137), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 164, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8872105), ('loss', 0.43385625), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 165, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8889728), ('loss', 0.43093997), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 166, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8889728), ('loss', 0.42823416), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 167, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8902316), ('loss', 0.42553663), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 168, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.89073515), ('loss', 0.4227917), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 169, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8924975), ('loss', 0.41997185), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 170, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.89274925), ('loss', 0.41709927), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 171, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.893001), ('loss', 0.4145312), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 172, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8942598), ('loss', 0.4119505), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 173, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8952669), ('loss', 0.40900493), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 174, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8965257), ('loss', 0.40641615), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 175, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.89677745), ('loss', 0.4037558), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 176, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.8975327), ('loss', 0.4012041), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 177, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.89803624), ('loss', 0.39859882), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 178, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.89879155), ('loss', 0.3958516), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 179, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.90080565), ('loss', 0.3932866), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 180, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.90080565), ('loss', 0.3907706), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 181, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9023162), ('loss', 0.38817278), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 182, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9030715), ('loss', 0.38568747), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 183, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.90609264), ('loss', 0.38301656), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 184, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9070997), ('loss', 0.38068485), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 185, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9076032), ('loss', 0.3781217), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 186, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9091138), ('loss', 0.37576813), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 187, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.91087615), ('loss', 0.37309945), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 188, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9123867), ('loss', 0.37072238), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 189, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9136455), ('loss', 0.3682584), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 190, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.91515607), ('loss', 0.36582512), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 191, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9156596), ('loss', 0.36355287), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 192, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.91691846), ('loss', 0.36108962), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 193, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.918429), ('loss', 0.35886675), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 194, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9186808), ('loss', 0.35629785), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 195, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.92019135), ('loss', 0.3540573), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 196, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.92019135), ('loss', 0.35188788), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 197, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.92119837), ('loss', 0.3494216), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 198, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.9219537), ('loss', 0.34729946), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 199, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.92220545), ('loss', 0.3448375), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Round 200, Metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.92346424), ('loss', 0.3426313), ('num_examples', 3972), ('num_batches', 126)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "\n",
            "Model saved to /content/drive/MyDrive/retinal_disease_model_.h5\n",
            "\n",
            "\n",
            "Found 828 images belonging to 7 classes.\n",
            "32/32 [==============================] - 5s 134ms/step - loss: 0.7568 - accuracy: 0.8320\n",
            "Validation Loss: 0.7568, Validation Accuracy: 0.8320\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load the saved model\n",
        "model_path = '/content/drive/MyDrive/retinal_disease_model_convnext.h5'  # Replace with your saved model path\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "# Step 2: Load and preprocess the image\n",
        "image_path = '/content/drive/MyDrive/classified_image/Age related Macular Degeneration/0_1kIM_14_ARMD.png'  # Update with the correct path\n",
        "img = image.load_img(image_path, target_size=(224, 224))  # Resize to match model's input\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array = img_array / 255.0  # Normalize image pixels to [0, 1]\n",
        "\n",
        "# Step 3: Predict the class\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "confidence = predictions[0][predicted_class] * 100\n",
        "class_labels = [\n",
        "    \"Age-related Macular Degeneration\",\n",
        "    \"Cataract\",\n",
        "    \"Diabetes\",\n",
        "    \"Glaucoma\",\n",
        "    \"Hypertension\",\n",
        "    \"Normal\",\n",
        "    \"Pathological Myopia\"\n",
        "]  # Update with your dataset's class names\n",
        "\n",
        "print(f\"Predicted class label: {class_labels[predicted_class[0]]}\")\n",
        "\n",
        "print(f\"Confidence: {confidence:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "TkCQxpzyIlSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7988673a-d280-41ff-ddf5-a68e15e78643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted Disease: Age-related Macular Degeneration\n",
            "Confidence: 89.45%\n",
            "      \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}