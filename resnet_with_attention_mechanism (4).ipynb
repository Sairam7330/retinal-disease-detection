{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vZfFjZmhoHfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce1124bc-c21d-4d84-9919-d543b676c6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "puFpDPEkOwJO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZk_SNp5wfgs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_path = '/content/drive/MyDrive/training'\n",
        "class_names = os.listdir(data_path)\n",
        "num_classes = len(class_names)\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_path = os.path.join(data_path, class_name)\n",
        "    for image_name in os.listdir(class_path):\n",
        "        image_path = os.path.join(class_path, image_name)\n",
        "        try:\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None:\n",
        "                raise ValueError(f\"Invalid image file: {image_path}\")\n",
        "            image = cv2.resize(image, (224, 224))\n",
        "            data.append(image)\n",
        "            labels.append(class_names.index(class_name))\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image: {image_path}\")\n",
        "            print(e)\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyE-AQhxYiTq"
      },
      "source": [
        "Splitting the dataset into Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6sNC13I1eQX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfMXth8T1hD3"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.astype('float32')\n",
        "test_data = test_data.astype('float32')\n",
        "\n",
        "mean = np.mean(train_data, axis=(0, 1, 2))\n",
        "std = np.std(train_data, axis=(0, 1, 2))\n",
        "\n",
        "train_data = (train_data - mean) / std\n",
        "test_data = (test_data - mean) / std\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSc-hTiUYpRg"
      },
      "source": [
        "Installing the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIStQiSh2O6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7dc948-af0d-405a-90d5-059cabe3fd4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.66.2)\n",
            "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
            "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.2.0 (from tensorflow)\n",
            "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Collecting namex (from keras>=3.2.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
            "Collecting optree (from keras>=3.2.0->tensorflow)\n",
            "  Downloading optree-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m235.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Downloading optree-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: namex, optree, ml-dtypes, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.17.0 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.6.0 ml-dtypes-0.4.1 namex-0.0.8 optree-0.13.0 tensorboard-2.17.1 tensorflow-2.17.0\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade keras\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_labels),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n"
      ],
      "metadata": {
        "id": "1z6_6PpoGdUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "resnet and attention mechanism"
      ],
      "metadata": {
        "id": "SLtxhfaflKz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Multiply, Conv2D, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras import regularizers\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained ResNet50 model without the top layers\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Attention mechanism (Channel Attention)\n",
        "def attention_module(input_tensor):\n",
        "    filters = input_tensor.shape[-1]\n",
        "    gap = GlobalAveragePooling2D()(input_tensor)\n",
        "    dense_1 = Dense(filters // 8, activation='relu')(gap)\n",
        "    dense_2 = Dense(filters, activation='sigmoid')(dense_1)\n",
        "    scale = Reshape((1, 1, filters))(dense_2)\n",
        "    return Multiply()([input_tensor, scale])\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = attention_module(x)  # Apply the attention mechanism\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)  # L2 Regularization\n",
        "x = BatchNormalization()(x)  # Add Batch Normalization\n",
        "x = Dropout(0.5)(x)  # Dropout to reduce overfitting\n",
        "predictions = Dense(num_classes, activation='softmax')(x)  # Softmax activation for multi-class classification\n",
        "\n",
        "# Define the complete model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base model layers for initial training\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Learning rate scheduler function\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.1))\n",
        "\n",
        "# Callbacks for learning rate reduction, early stopping, and learning rate scheduling\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.2, min_lr=1e-5)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_scheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(test_data, test_labels),\n",
        "    callbacks=[lr_reduction, early_stopping, lr_scheduler]\n",
        ")\n",
        "\n",
        "# Fine-tuning: Unfreeze base model layers and continue training\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile the model with a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Continue training (fine-tuning)\n",
        "history_fine_tune = model.fit(\n",
        "    train_data,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(test_data, test_labels),\n",
        "    callbacks=[lr_reduction, early_stopping, lr_scheduler]\n",
        ")\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "loss, accuracy = model.evaluate(test_data, test_labels)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Save the model for later use\n",
        "model.save('/content/retinal_disease_model_resnet_attention.h5')\n"
      ],
      "metadata": {
        "id": "TbfM-yDAlJid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6688da-6f60-490f-b633-4fd7d2cf5e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 609ms/step - accuracy: 0.6142 - loss: 2.0881 - val_accuracy: 0.6927 - val_loss: 1.2869 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 595ms/step - accuracy: 0.7398 - loss: 1.1337 - val_accuracy: 0.7608 - val_loss: 0.9647 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 593ms/step - accuracy: 0.7803 - loss: 0.9133 - val_accuracy: 0.7225 - val_loss: 1.0114 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 601ms/step - accuracy: 0.8023 - loss: 0.7708 - val_accuracy: 0.7747 - val_loss: 0.8329 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 601ms/step - accuracy: 0.8261 - loss: 0.7044 - val_accuracy: 0.6027 - val_loss: 1.5574 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 598ms/step - accuracy: 0.8324 - loss: 0.6600 - val_accuracy: 0.6718 - val_loss: 1.1530 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - accuracy: 0.8371 - loss: 0.5988\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 595ms/step - accuracy: 0.8371 - loss: 0.5988 - val_accuracy: 0.6017 - val_loss: 1.9315 - learning_rate: 2.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 602ms/step - accuracy: 0.8716 - loss: 0.4890 - val_accuracy: 0.8493 - val_loss: 0.5426 - learning_rate: 2.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 604ms/step - accuracy: 0.8983 - loss: 0.4214 - val_accuracy: 0.8364 - val_loss: 0.5640 - learning_rate: 2.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 600ms/step - accuracy: 0.9057 - loss: 0.3840 - val_accuracy: 0.8449 - val_loss: 0.5474 - learning_rate: 2.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 600ms/step - accuracy: 0.9114 - loss: 0.3555 - val_accuracy: 0.8598 - val_loss: 0.5164 - learning_rate: 1.8097e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 608ms/step - accuracy: 0.9137 - loss: 0.3367 - val_accuracy: 0.8528 - val_loss: 0.5066 - learning_rate: 1.6375e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 609ms/step - accuracy: 0.9195 - loss: 0.3227 - val_accuracy: 0.8518 - val_loss: 0.5266 - learning_rate: 1.4816e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 607ms/step - accuracy: 0.9268 - loss: 0.2940 - val_accuracy: 0.8429 - val_loss: 0.5363 - learning_rate: 1.3406e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - accuracy: 0.9289 - loss: 0.2826\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.4261228099931033e-05.\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 600ms/step - accuracy: 0.9289 - loss: 0.2826 - val_accuracy: 0.8503 - val_loss: 0.5335 - learning_rate: 2.4261e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 601ms/step - accuracy: 0.9292 - loss: 0.2671 - val_accuracy: 0.8652 - val_loss: 0.4777 - learning_rate: 2.1952e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 607ms/step - accuracy: 0.9375 - loss: 0.2533 - val_accuracy: 0.8662 - val_loss: 0.4704 - learning_rate: 1.9863e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 606ms/step - accuracy: 0.9396 - loss: 0.2530 - val_accuracy: 0.8637 - val_loss: 0.4708 - learning_rate: 1.7973e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 605ms/step - accuracy: 0.9429 - loss: 0.2394 - val_accuracy: 0.8647 - val_loss: 0.4731 - learning_rate: 1.6263e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 604ms/step - accuracy: 0.9399 - loss: 0.2439 - val_accuracy: 0.8647 - val_loss: 0.4685 - learning_rate: 1.4715e-05\n",
            "Epoch 1/10\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m727s\u001b[0m 3s/step - accuracy: 0.6414 - loss: 1.5194 - val_accuracy: 0.3983 - val_loss: 3.5651 - learning_rate: 1.0000e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 3s/step - accuracy: 0.9407 - loss: 0.2626 - val_accuracy: 0.5574 - val_loss: 2.1786 - learning_rate: 1.0000e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 3s/step - accuracy: 0.9874 - loss: 0.1305 - val_accuracy: 0.8901 - val_loss: 0.4086 - learning_rate: 1.0000e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 3s/step - accuracy: 0.9921 - loss: 0.1048 - val_accuracy: 0.9493 - val_loss: 0.2495 - learning_rate: 1.0000e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m676s\u001b[0m 3s/step - accuracy: 0.9970 - loss: 0.0876 - val_accuracy: 0.9552 - val_loss: 0.2322 - learning_rate: 1.0000e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 3s/step - accuracy: 0.9979 - loss: 0.0821 - val_accuracy: 0.9528 - val_loss: 0.2520 - learning_rate: 1.0000e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 3s/step - accuracy: 0.9983 - loss: 0.0779 - val_accuracy: 0.9612 - val_loss: 0.2317 - learning_rate: 1.0000e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m683s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0740 - val_accuracy: 0.9622 - val_loss: 0.2242 - learning_rate: 1.0000e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m180/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3:06\u001b[0m 3s/step - accuracy: 0.9995 - loss: 0.0724"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}